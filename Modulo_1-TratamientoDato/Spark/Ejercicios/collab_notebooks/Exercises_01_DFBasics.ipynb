{"cells":[{"cell_type":"markdown","metadata":{"id":"BNkZfzfxGZ0z"},"source":["# DataFrames Basics Exercises"]},{"cell_type":"markdown","source":["## Prerrequisites"],"metadata":{"id":"AQieQ5pkGfNm"}},{"cell_type":"markdown","source":["Install Spark and Java in VM"],"metadata":{"id":"HelxRmCPGpql"}},{"cell_type":"code","source":["# install Java8\n","!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n","# download spark3.0.1\n","!wget -q https://apache.osuosl.org/spark/spark-3.3.1/spark-3.3.1-bin-hadoop2.tgz"],"metadata":{"id":"9Cn3c-ywGtDV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ls -l # check the .tgz is there"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"D95sNcJfGvyV","executionInfo":{"status":"ok","timestamp":1670456814523,"user_tz":-60,"elapsed":7,"user":{"displayName":"Pablo Pons","userId":"14943288678703205331"}},"outputId":"e94044e3-ef55-433c-dfb0-fd86557ffb97"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["total 267684\n","drwxr-xr-x 1 root root      4096 Dec  6 14:35 \u001b[0m\u001b[01;34msample_data\u001b[0m/\n","-rw-r--r-- 1 root root 274099817 Oct 15 10:53 spark-3.3.1-bin-hadoop2.tgz\n"]}]},{"cell_type":"code","source":["# unzip it\n","!tar xf spark-3.3.1-bin-hadoop2.tgz"],"metadata":{"id":"qtBMGi7EGvwN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install -q findspark"],"metadata":{"id":"6JO331NrGvtt"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Defining the environment"],"metadata":{"id":"02epIDkbG24d"}},{"cell_type":"code","source":["import os\n","os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n","os.environ[\"SPARK_HOME\"] = \"/content/spark-3.3.1-bin-hadoop2\"\n","os.environ[\"PYSPARK_SUBMIT_ARGS\"] = \"--master local[*] pyspark-shell\""],"metadata":{"id":"qmON5zHJG4-m"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WgvNJQOAGZ00"},"source":["Start Spark Session\n","\n","---"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"siaPZq4XGZ00","executionInfo":{"status":"ok","timestamp":1670456831312,"user_tz":-60,"elapsed":9230,"user":{"displayName":"Pablo Pons","userId":"14943288678703205331"}},"outputId":"6ca941e7-feed-4609-c602-178830155d2c"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'3.3.1'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":7}],"source":["import findspark\n","findspark.init(\"spark-3.3.1-bin-hadoop2\")# SPARK_HOME\n","\n","from pyspark.sql import SparkSession\n","\n","# create the session\n","spark = SparkSession \\\n","        .builder \\\n","        .appName(\"DataFramesBasics Exercises\") \\\n","        .master(\"local[*]\") \\\n","        .getOrCreate()\n","\n","spark.version"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":219},"id":"nsBkpLh6GZ01","executionInfo":{"status":"ok","timestamp":1670445013413,"user_tz":-60,"elapsed":2301,"user":{"displayName":"Pablo Pons","userId":"14943288678703205331"}},"outputId":"566b7993-0fe2-4352-cb0c-c0b45b96cdad"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<pyspark.sql.session.SparkSession at 0x7f14fe863c10>"],"text/html":["\n","            <div>\n","                <p><b>SparkSession - in-memory</b></p>\n","                \n","        <div>\n","            <p><b>SparkContext</b></p>\n","\n","            <p><a href=\"http://bae4ada9eee7:4040\">Spark UI</a></p>\n","\n","            <dl>\n","              <dt>Version</dt>\n","                <dd><code>v3.3.1</code></dd>\n","              <dt>Master</dt>\n","                <dd><code>local[*]</code></dd>\n","              <dt>AppName</dt>\n","                <dd><code>Introductory Exercises</code></dd>\n","            </dl>\n","        </div>\n","        \n","            </div>\n","        "]},"metadata":{},"execution_count":8}],"source":["spark"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Bqu4fQnNGZ02"},"outputs":[],"source":["# For Pandas conversion optimization\n","spark.conf.set(\"spark.sql.execution.arrow.enabled\", \"true\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-9DDmYQKGZ02"},"outputs":[],"source":["# Import sql functions\n","from pyspark.sql.functions import *"]},{"cell_type":"markdown","source":["Download datasets"],"metadata":{"id":"NYrtXWZIHKMt"}},{"cell_type":"code","source":["!mkdir -p dataset\n","!wget -q https://raw.githubusercontent.com/paponsro/spark_edem_2022/master/datasets/movies.json -P /dataset\n","!wget -q https://raw.githubusercontent.com/paponsro/spark_edem_2022/master/datasets/cars.json -P /dataset\n","!wget -q https://github.com/masfworld/datahack_docker/raw/master/zeppelin/data/bank.csv -P /dataset\n","!wget -q https://github.com/masfworld/datahack_docker/raw/master/zeppelin/data/vehicles.csv -P /dataset"],"metadata":{"id":"2lkKBm3CHL-l"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sxWVtHu5GZ02"},"source":["## DataFrames Basics Exercises"]},{"cell_type":"markdown","source":["1) Create a manual DF describing smartphones\n","  - maker\n","  - model\n","  - screen dimension\n","  - camera megapixels\n","  \n","2) Read another file from the dataset/ folder, e.g. movies.json\n","  - print its schema\n","  - count the number of rows, call count()\n","\n","3) Take a look to vehicles.csv. Read the file to a DF but this time with your own schema"],"metadata":{"id":"rZt5nAVLRmeF"}},{"cell_type":"code","source":[],"metadata":{"id":"DF-WHVfjRq49"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Columns and Expressions Exercises"],"metadata":{"id":"99pcX8w3SVdO"}},{"cell_type":"markdown","source":["1. Read the movies DF and select 2 columns of your choice\n","2. Create another column summing up the total profit of the movies = US_Gross + Worldwide_Gross + DVD sales. Are you pbtaining nulls? How you can solve it?\n","3. Select all COMEDY movies with IMDB rating above 6\n","\n","Use as many versions as possible"],"metadata":{"id":"Q4LymMG0Sg_l"}},{"cell_type":"code","source":[],"metadata":{"id":"zggMCTkASeO0"},"execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3.10.0 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.0"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"ff1af5cda0bea4fe5c4ebc1f94ab9f13d8998f98d08e16d8aba48673b9d00116"}},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}