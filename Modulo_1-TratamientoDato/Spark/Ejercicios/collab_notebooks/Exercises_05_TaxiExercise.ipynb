{"cells":[{"cell_type":"markdown","metadata":{"id":"BNkZfzfxGZ0z"},"source":["# Taxi Exercise"]},{"cell_type":"markdown","source":["## Prerrequisites"],"metadata":{"id":"AQieQ5pkGfNm"}},{"cell_type":"markdown","source":["Install Spark and Java in VM"],"metadata":{"id":"HelxRmCPGpql"}},{"cell_type":"code","source":["# install Java8\n","!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n","# download spark3.0.1\n","!wget -q https://apache.osuosl.org/spark/spark-3.3.1/spark-3.3.1-bin-hadoop2.tgz"],"metadata":{"id":"9Cn3c-ywGtDV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ls -l # check the .tgz is there"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"D95sNcJfGvyV","executionInfo":{"status":"ok","timestamp":1670666409845,"user_tz":-60,"elapsed":23,"user":{"displayName":"Pablo Pons","userId":"14943288678703205331"}},"outputId":"27b6a4e9-52bc-4cb9-8628-f6a7dbdde1d5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["total 267680\n","drwxr-xr-x 1 root root      4096 Dec  8 14:36 \u001b[0m\u001b[01;34msample_data\u001b[0m/\n","-rw-r--r-- 1 root root 274099817 Oct 15 10:53 spark-3.3.1-bin-hadoop2.tgz\n"]}]},{"cell_type":"code","source":["# unzip it\n","!tar xf spark-3.3.1-bin-hadoop2.tgz"],"metadata":{"id":"qtBMGi7EGvwN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install -q findspark"],"metadata":{"id":"6JO331NrGvtt"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Defining the environment"],"metadata":{"id":"02epIDkbG24d"}},{"cell_type":"code","source":["import os\n","os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n","os.environ[\"SPARK_HOME\"] = \"/content/spark-3.3.1-bin-hadoop2\"\n","os.environ[\"PYSPARK_SUBMIT_ARGS\"] = \"--master local[*] pyspark-shell\""],"metadata":{"id":"qmON5zHJG4-m"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WgvNJQOAGZ00"},"source":["Start Spark Session\n","\n","---"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"siaPZq4XGZ00","executionInfo":{"status":"ok","timestamp":1670666427737,"user_tz":-60,"elapsed":9447,"user":{"displayName":"Pablo Pons","userId":"14943288678703205331"}},"outputId":"4bf8c7ce-9323-4449-b264-5696cfabdf10"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'3.3.1'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":6}],"source":["import findspark\n","findspark.init(\"spark-3.3.1-bin-hadoop2\")# SPARK_HOME\n","\n","from pyspark.sql import SparkSession\n","\n","# create the session\n","spark = SparkSession \\\n","        .builder \\\n","        .appName(\"Window Partitioning Exercises\") \\\n","        .master(\"local[*]\") \\\n","        .getOrCreate()\n","\n","spark.version"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":219},"id":"nsBkpLh6GZ01","executionInfo":{"status":"ok","timestamp":1670666430458,"user_tz":-60,"elapsed":2732,"user":{"displayName":"Pablo Pons","userId":"14943288678703205331"}},"outputId":"06d33567-7e04-46a7-e984-6f8b994d561d"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<pyspark.sql.session.SparkSession at 0x7f4eb80c78b0>"],"text/html":["\n","            <div>\n","                <p><b>SparkSession - in-memory</b></p>\n","                \n","        <div>\n","            <p><b>SparkContext</b></p>\n","\n","            <p><a href=\"http://e8464eecf147:4040\">Spark UI</a></p>\n","\n","            <dl>\n","              <dt>Version</dt>\n","                <dd><code>v3.3.1</code></dd>\n","              <dt>Master</dt>\n","                <dd><code>local[*]</code></dd>\n","              <dt>AppName</dt>\n","                <dd><code>Window Partitioning Exercises</code></dd>\n","            </dl>\n","        </div>\n","        \n","            </div>\n","        "]},"metadata":{},"execution_count":7}],"source":["spark"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Bqu4fQnNGZ02"},"outputs":[],"source":["# For Pandas conversion optimization\n","spark.conf.set(\"spark.sql.execution.arrow.enabled\", \"true\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-9DDmYQKGZ02"},"outputs":[],"source":["# Import sql functions\n","from pyspark.sql.functions import *"]},{"cell_type":"markdown","source":["Download datasets"],"metadata":{"id":"NYrtXWZIHKMt"}},{"cell_type":"code","source":["!mkdir -p dataset\n","!wget -q https://raw.githubusercontent.com/paponsro/spark_edem_2022/master/datasets/taxi_data.csv -P /dataset\n","!wget -q https://raw.githubusercontent.com/paponsro/spark_edem_2022/master/datasets/taxi_zones.csv -P /dataset"],"metadata":{"id":"FUUWbuUAefth"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Load datasets"],"metadata":{"id":"S9qmbKPae1I4"}},{"cell_type":"code","source":["taxiDF = spark.read \\\n","    .option(\"header\", \"true\") \\\n","    .option(\"inferSchema\", \"true\") \\\n","    .csv(\"/dataset/taxi_data.csv\")\n","\n","taxiDF.printSchema()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"isNbuv4ge6Uv","executionInfo":{"status":"ok","timestamp":1670666578043,"user_tz":-60,"elapsed":3754,"user":{"displayName":"Pablo Pons","userId":"14943288678703205331"}},"outputId":"64508c45-a1d1-4d5c-b4bb-daa2d6608580"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["root\n"," |-- VendorID: integer (nullable = true)\n"," |-- tpep_pickup_datetime: timestamp (nullable = true)\n"," |-- tpep_dropoff_datetime: timestamp (nullable = true)\n"," |-- passenger_count: integer (nullable = true)\n"," |-- trip_distance: double (nullable = true)\n"," |-- RatecodeID: integer (nullable = true)\n"," |-- store_and_fwd_flag: string (nullable = true)\n"," |-- PULocationID: integer (nullable = true)\n"," |-- DOLocationID: integer (nullable = true)\n"," |-- payment_type: integer (nullable = true)\n"," |-- fare_amount: double (nullable = true)\n"," |-- extra: double (nullable = true)\n"," |-- mta_tax: double (nullable = true)\n"," |-- tip_amount: double (nullable = true)\n"," |-- tolls_amount: double (nullable = true)\n"," |-- improvement_surcharge: double (nullable = true)\n"," |-- total_amount: double (nullable = true)\n","\n"]}]},{"cell_type":"code","source":["taxiZonesDF = spark.read \\\n","    .option(\"header\", \"true\") \\\n","    .option(\"inferSchema\", \"true\") \\\n","    .csv(\"/dataset/taxi_zones.csv\")\n","\n","taxiZonesDF.printSchema()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xcDUnwfPfKHs","executionInfo":{"status":"ok","timestamp":1670666621415,"user_tz":-60,"elapsed":1016,"user":{"displayName":"Pablo Pons","userId":"14943288678703205331"}},"outputId":"23c85968-6652-4033-f90b-0ee6b25baea5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["root\n"," |-- LocationID: integer (nullable = true)\n"," |-- Borough: string (nullable = true)\n"," |-- Zone: string (nullable = true)\n"," |-- service_zone: string (nullable = true)\n","\n"]}]},{"cell_type":"markdown","metadata":{"id":"sxWVtHu5GZ02"},"source":["## Taxi Exercise"]},{"cell_type":"markdown","source":["In this exercise we will be working with two DFs. The first one, taxiDf holds info about taxi rides per 2018 year. And the second, taxiZonesDF, have info about the Zones. Please load the DFs and print the schemas and two (or more) rows for more detailed info.\n","\n","The aim of the exercise is to answer the questions listed below."],"metadata":{"id":"rZt5nAVLRmeF"}},{"cell_type":"markdown","source":["## Questions:\n","\n"," 1. Which zones have the most pickups/dropoffs overall? Note there are many PULocationIDs per Zone?\n"," 2. What are the peak hours for taxi?\n"," 3. How are the trips distributed by length? Show stats like mean, max, min, etc. \n","    Then get the total trips for less/more than 30 km. Why are people taking the cab? For long or short trips?\n","    You can also try the same with different distances. Which is the expected value for threshold is we want to obtain more or less the same trips in long/short counting?\n"," 4. What are the peak hours for long/short trips?\n"," 5. What are the top 3 pickup/dropoff zones for long/short trips?\n"," 6. How are people paying for the ride, on long/short trips? Hint: the information about how good is the payment is in RatecodeID column.\n"," 7. How is the payment type (RatecodeId) evolving with time (in days)? Hint: use the column with pickup time info.\n","    Get the same info but with avg of ratecode and total trips per day."],"metadata":{"id":"8psiH85Df774"}},{"cell_type":"code","source":[],"metadata":{"id":"DF-WHVfjRq49"},"execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3.10.0 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.0"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"ff1af5cda0bea4fe5c4ebc1f94ab9f13d8998f98d08e16d8aba48673b9d00116"}},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}