{"cells":[{"cell_type":"markdown","metadata":{"id":"BNkZfzfxGZ0z"},"source":["# UDFs and Partitioning"]},{"cell_type":"markdown","source":["## Prerrequisites"],"metadata":{"id":"AQieQ5pkGfNm"}},{"cell_type":"markdown","source":["Install Spark and Java in VM"],"metadata":{"id":"HelxRmCPGpql"}},{"cell_type":"code","source":["# install Java8\n","!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n","# download spark3.0.1\n","!wget -q https://apache.osuosl.org/spark/spark-3.3.1/spark-3.3.1-bin-hadoop2.tgz"],"metadata":{"id":"9Cn3c-ywGtDV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ls -l # check the .tgz is there"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"D95sNcJfGvyV","executionInfo":{"status":"ok","timestamp":1670526525234,"user_tz":-60,"elapsed":208,"user":{"displayName":"Pablo Pons","userId":"14943288678703205331"}},"outputId":"1eb63e78-8f9e-4827-8e6d-950c53c5a9e6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["total 267680\n","drwxr-xr-x 1 root root      4096 Dec  7 14:41 \u001b[0m\u001b[01;34msample_data\u001b[0m/\n","-rw-r--r-- 1 root root 274099817 Oct 15 10:53 spark-3.3.1-bin-hadoop2.tgz\n"]}]},{"cell_type":"code","source":["# unzip it\n","!tar xf spark-3.3.1-bin-hadoop2.tgz"],"metadata":{"id":"qtBMGi7EGvwN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install -q findspark"],"metadata":{"id":"6JO331NrGvtt"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Defining the environment"],"metadata":{"id":"02epIDkbG24d"}},{"cell_type":"code","source":["import os\n","os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n","os.environ[\"SPARK_HOME\"] = \"/content/spark-3.3.1-bin-hadoop2\"\n","os.environ[\"PYSPARK_SUBMIT_ARGS\"] = \"--master local[*] pyspark-shell\""],"metadata":{"id":"qmON5zHJG4-m"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WgvNJQOAGZ00"},"source":["Start Spark Session\n","\n","---"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"siaPZq4XGZ00","executionInfo":{"status":"ok","timestamp":1670526544215,"user_tz":-60,"elapsed":10529,"user":{"displayName":"Pablo Pons","userId":"14943288678703205331"}},"outputId":"e89c88b0-a979-4c88-cb7f-76c9b7572840"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'3.3.1'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":6}],"source":["import findspark\n","findspark.init(\"spark-3.3.1-bin-hadoop2\")# SPARK_HOME\n","\n","from pyspark.sql import SparkSession\n","\n","# create the session\n","spark = SparkSession \\\n","        .builder \\\n","        .appName(\"Window Partitioning Exercises\") \\\n","        .master(\"local[*]\") \\\n","        .getOrCreate()\n","\n","spark.version"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":219},"id":"nsBkpLh6GZ01","executionInfo":{"status":"ok","timestamp":1670526546378,"user_tz":-60,"elapsed":2184,"user":{"displayName":"Pablo Pons","userId":"14943288678703205331"}},"outputId":"0115a362-9bab-4126-93b0-e1546c2f1740"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<pyspark.sql.session.SparkSession at 0x7f71a73fc160>"],"text/html":["\n","            <div>\n","                <p><b>SparkSession - in-memory</b></p>\n","                \n","        <div>\n","            <p><b>SparkContext</b></p>\n","\n","            <p><a href=\"http://d650ef38ecd6:4040\">Spark UI</a></p>\n","\n","            <dl>\n","              <dt>Version</dt>\n","                <dd><code>v3.3.1</code></dd>\n","              <dt>Master</dt>\n","                <dd><code>local[*]</code></dd>\n","              <dt>AppName</dt>\n","                <dd><code>Window Partitioning Exercises</code></dd>\n","            </dl>\n","        </div>\n","        \n","            </div>\n","        "]},"metadata":{},"execution_count":7}],"source":["spark"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Bqu4fQnNGZ02"},"outputs":[],"source":["# For Pandas conversion optimization\n","spark.conf.set(\"spark.sql.execution.arrow.enabled\", \"true\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-9DDmYQKGZ02"},"outputs":[],"source":["# Import sql functions\n","from pyspark.sql.functions import *"]},{"cell_type":"markdown","source":["Download datasets"],"metadata":{"id":"NYrtXWZIHKMt"}},{"cell_type":"code","source":["!mkdir -p /dataset\n","!wget -q https://github.com/masfworld/datahack_docker/raw/master/zeppelin/data/bank.csv -P /dataset\n","!wget -q https://github.com/masfworld/datahack_docker/raw/master/zeppelin/data/vehicles.csv -P /dataset\n","!wget -q https://github.com/masfworld/datahack_docker/raw/master/zeppelin/data/characters.csv -P /dataset\n","!wget -q https://github.com/masfworld/datahack_docker/raw/master/zeppelin/data/planets.csv -P /dataset\n","!wget -q https://github.com/masfworld/datahack_docker/raw/master/zeppelin/data/species.csv -P /dataset\n","!ls /dataset"],"metadata":{"id":"2lkKBm3CHL-l","executionInfo":{"status":"ok","timestamp":1670526548752,"user_tz":-60,"elapsed":2394,"user":{"displayName":"Pablo Pons","userId":"14943288678703205331"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"d68e40c1-01c9-45bc-8763-68ad13920fdd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["bank.csv  characters.csv  planets.csv  species.csv  vehicles.csv\n"]}]},{"cell_type":"markdown","metadata":{"id":"sxWVtHu5GZ02"},"source":["## UDFs and Partitioning Exercises"]},{"cell_type":"markdown","source":["1. Read other dataset and try the repartition/colaesce\n","2. Try one udf function of your choice among the DF you have read"],"metadata":{"id":"rZt5nAVLRmeF"}},{"cell_type":"code","source":[],"metadata":{"id":"DF-WHVfjRq49"},"execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3.10.0 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.0"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"ff1af5cda0bea4fe5c4ebc1f94ab9f13d8998f98d08e16d8aba48673b9d00116"}},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}