{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Regresión Semana 2: Regresión múltiple (descenso por gradiente)\n",
        "\n",
        "En el primer cuaderno exploramos la regresión múltiple usando scikit-learn. Ahora usaremos la librería **pandas** junto con **numpy** para resolver los pesos de regresión con descenso de gradiente.\n",
        "\n",
        "En este notebook cubriremos la estimación de los pesos de regresión múltiple mediante el descenso por gradiente.  harás:\n",
        "\n",
        "* Añadir una columna constante de 1's para tener en cuenta el intercepto.\n",
        "* Convertir un df en un array Numpy\n",
        "* Escribir una función predict_output() usando Numpy\n",
        "* Escribir una función numpy para calcular la derivada de los pesos de regresión con respecto a una única característica.\n",
        "* Escribir una función de descenso del gradiente para calcular los pesos de regresión dado un vector inicial de pesos, tamaño de paso y tolerancia.\n",
        "* Utilizar la función de descenso de gradiente para estimar los pesos de regresión para múltiples características."
      ],
      "metadata": {
        "id": "8ZmuHw4VcOaW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Z2m1urLEFgf9"
      },
      "outputs": [],
      "source": [
        "#Importamos las librerías necesarias\n",
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cargamos los datos"
      ],
      "metadata": {
        "id": "C5Om5tAjeBgS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Cargamos los datos\n",
        "\n",
        "dtype_dict = {'bathrooms':float, 'waterfront':int, 'sqft_above':int, 'sqft_living15':float, 'grade':int, \n",
        "              'yr_renovated':int, 'price':float, 'bedrooms':float, 'zipcode':str, 'long':float, 'sqft_lot15':float, \n",
        "              'sqft_living':float, 'floors':str, 'condition':int, 'lat':float, 'date':str, 'sqft_basement':int, \n",
        "              'yr_built':int, 'id':str, 'sqft_lot':int, 'view':int}\n",
        "\n",
        "df_train = pd.read_csv('/content/kc_house_train_data.csv', dtype= dtype_dict)\n",
        "\n",
        "df_test = pd.read_csv('/content/kc_house_test_data.csv', dtype= dtype_dict)\n",
        "\n",
        "df = pd.read_csv('/content/kc_house_data.csv', dtype= dtype_dict)"
      ],
      "metadata": {
        "id": "RFO1Kyi2dvgl"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Convertir a Numpy Array"
      ],
      "metadata": {
        "id": "S21t80rZfJLH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aunque **Pandas** ofrece una serie de beneficios a los usuarios (especialmente cuando se utiliza en Big Data) para entender los detalles de la implementación de algoritmos es importante trabajar con una librería que permita realizar operaciones matriciales de forma directa (y optimizada). Numpy es una solución de Python para trabajar con matrices (o cualquier \"array\" multidimensional).\n",
        "\n",
        "El valor predicho dados los pesos y las características, es simplemente el **[producto escalar](https://es.wikipedia.org/wiki/Producto_escalar)** entre el vector de características y el de pesos. Del mismo modo, si colocamos todas las características fila por fila en una matriz, el valor predicho para todas las observaciones puede calcularse multiplicando la \"matriz de características\" por el \"vector de pesos\".\n",
        "\n",
        "Primero tenemos que tomar el Dataframe de nuestros datos y convertirlo en un array 2D de numpy (también llamado **matriz**).\n",
        "\n",
        "Ahora escribiremos una función que aceptará un DataFrame, una lista de nombres de columnas (por ejemplo ['sqft_living', 'bedrooms']) y una variable objetivo, por ejemplo ('price') y devolverá dos cosas:\n",
        "\n",
        "* Una matriz numpy cuyas columnas son las características deseadas más una columna constante (así creamos un 'intercepto')\n",
        "* Una matriz numpy que contiene los valores de la salida"
      ],
      "metadata": {
        "id": "fSkZUISwfarn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_numpy_data(df, features, output):\n",
        "\n",
        "    \n",
        "    features_matrix = df[features] \n",
        "    \n",
        "    # así es como se añade una columna constante a un df\n",
        "    features_matrix['constant'] = 1\n",
        "    \n",
        "    # añade la columna 'constant' al principio de la lista de características para que podamos extraerla junto con las demás:\n",
        "    #features.insert(0, 'constant')\n",
        "    features = ['constant'] + features # Así es como combinamos dos listas\n",
        "\n",
        "    # seleccionar las columnas de df dadas por la lista features en el df (ahora incluyendo la constante):\n",
        "    features_matrix = features_matrix[features]\n",
        "\n",
        "    #Convertimos el dataframe a un matriz de numpy\n",
        "    features_matrix = np.array(features_matrix)\n",
        "\n",
        "    #Cogemos las características para la salida\n",
        "    output_array = df[output]\n",
        "\n",
        "    #Convertimos el array a numpy\n",
        "    output_array = np.array(output_array)\n",
        "    \n",
        "    return(features_matrix, output_array)\n"
      ],
      "metadata": {
        "id": "he0kN9USe-dM"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para probar la función anterior, utilizamos la característica 'sqft_living' , una constante como nuestras características y el precio como nuestro output."
      ],
      "metadata": {
        "id": "H2cSPH91ikfI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "(example_features, example_output) = get_numpy_data(df, ['sqft_living'], 'price') \n",
        "print(example_features[0,:])\n",
        "print(example_output[0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qvKSKstnidsM",
        "outputId": "28da00c4-d7ed-49ce-b344-3043903ef888"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1.00e+00 1.18e+03]\n",
            "221900.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Predicción del output dados los pesos de regresión\n",
        "\n"
      ],
      "metadata": {
        "id": "rmVjcXeDjT5I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Supongamos que tenemos los pesos [1.0, 1.0] y las características [1.0, 1180.0] y queremos calcular la predicción de salida 1.0\\*1.0 + 1.0\\*1180.0 = 1181.0 esto es el producto escalar (**DOT PRODUCT**) entre estas dos matrices. Si son matrices numpy podemos utilizar np.dot() para calcular esto:"
      ],
      "metadata": {
        "id": "ifk2z9BukSoD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "my_weights = np.array([1., 1.]) # pesos ejemplo\n",
        "my_features = example_features[0,] # Utilizaremos el primer data point\n",
        "predicted_value = np.dot(my_features, my_weights)\n",
        "print(predicted_value)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oaJLqTpckXmx",
        "outputId": "086872e4-902f-4c1e-b4ad-afd903ceabd1"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1181.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Si la matriz de características (incluyendo una columna de 1s para la constante) se almacena como un array 2D(o matriz) y los pesos de regresión se almacenan como un array 1D, entonces la salida predicha es simplemente el producto escalar entre la matriz de características y los pesos (con los pesos a la derecha). \n",
        "\n",
        "Escribe una función '**predict_output**' que acepte una matriz 2D 'feature_matrix' y una matriz 1D 'weights' y devuelva una matriz 1D 'predictions'."
      ],
      "metadata": {
        "id": "1eiTA1xhkWQ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_output(feature_matrix, weights):\n",
        "    #supongamos que feature_matrix es una matriz numpy que contiene las características como columnas y weights es la matriz numpy \n",
        "    # create el vector de predicciones utilizando np.dot()\n",
        "\n",
        "    predictions = np.dot(feature_matrix, weights)\n",
        "    return(predictions)\n"
      ],
      "metadata": {
        "id": "X3-qVDHQi53R"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Si quieres testear tu código, ejecuta la siguiente celda"
      ],
      "metadata": {
        "id": "R6y2nBijk7XO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_predictions = predict_output(example_features, my_weights)\n",
        "print (test_predictions[0]) # debería ser 1181.0\n",
        "print (test_predictions[1]) # debería 2571.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qa0gx_p5j-fM",
        "outputId": "bdebf40a-a924-434f-b052-42c41e89605d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1181.0\n",
            "2571.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cálculo de la Derivada"
      ],
      "metadata": {
        "id": "px3K5L--lKhA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora vamos a pasar a calcular la derivada de la función de coste de regresión. Recordemos que la función de coste es la Suma del Cuadrado de los resíduos entre el valor predicho y el valor real\n",
        "\n",
        "Dado que la derivada de una suma es la suma de las derivadas, podemos calcular la derivada para un único punto de datos y, a continuación, sumar los puntos de datos. Podemos escribir la diferencia al cuadrado entre la salida observada y la salida predicha para un solo punto de la siguiente manera:\n",
        "\n",
        "(w[0]\\*[CONSTANT] + w[1]\\*[feature_1] + ... + w[i] \\*[feature_i] + ... +  w[k]\\*[feature_k] - output)^2\n",
        "\n",
        "Donde tenemos k características y una constante. Así que la derivada con respecto al peso w[i] por la **[regla de la cadena](https://es.wikipedia.org/wiki/Regla_de_la_cadena)** es:\n",
        "\n",
        "2\\*(w[0]\\*[CONSTANT] + w[1]\\*[feature_1] + ... + w[i] \\*[feature_i] + ... +  w[k]\\*[feature_k] - output)\\* [feature_i]\n",
        "\n",
        "El término dentro de la paréntesis es sólo el error (diferencia entre la predicción y el output). Así que podemos reescribir esto como:\n",
        "\n",
        "2\\*error\\*[feature_i]\n",
        "\n",
        "Es decir, la derivada del peso de la característica i es la suma (sobre los puntos datos) de 2 veces el producto del error y la propia característica. En el caso de la constante, es el doble de la suma de los errores.\n",
        "\n",
        "Recordemos que el doble de la suma del producto de dos vectores es el doble del producto escalar de los dos vectores. Por lo tanto, la derivada para el peso de la característica_i es sólo dos veces el producto escalar entre los valores de la característica_i y los errores actuales. \n",
        "\n",
        "Con esto en mente complete la siguiente función derivada que calcula la derivada del peso dado el valor de la característica (sobre todos los puntos de datos) y los errores (sobre todos los puntos de datos).\n"
      ],
      "metadata": {
        "id": "ys1j2rnDlVmi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def feature_derivative(errors, feature):\n",
        "    # Supongamos que errors y feature son ambas matrices numpy de la misma longitud (número de puntos de datos).\n",
        "    # calcula el doble del producto punto de estos vectores como 'derivada' y devuelve el valor\n",
        "\n",
        "    derivative = 2*np.dot(errors, feature)\n",
        "    return(derivative)"
      ],
      "metadata": {
        "id": "PSmvYHtAlG_O"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para probar su feature_derivative ejecuta lo siguiente:"
      ],
      "metadata": {
        "id": "PD3seqcxnZcf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(example_features, example_output) = get_numpy_data(df, ['sqft_living'], 'price') \n",
        "\n",
        "my_weights = np.array([0., 0.]) # Esto hace todas las predicciones 0\n",
        "\n",
        "test_predictions = predict_output(example_features, my_weights) \n",
        "\n",
        "# 2 arrays numpy se pueden restar  con '-':\n",
        "errors = test_predictions - example_output #Errores de predicción en este caso es solo el example_output\n",
        "\n",
        "feature = example_features[:,0] #calculemos la derivada con respecto a 'constant', el \":\" indica \"todas las filas\"\n",
        "\n",
        "derivative = feature_derivative(errors, feature)\n",
        "print (derivative)\n",
        "\n",
        "print (-np.sum(example_output)*2) # debería dar lo mismo que arriba"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hzr5ZY6Bm6A3",
        "outputId": "324a88b7-2fdb-46f9-ee3d-bf9160a6c59d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-23345850016.0\n",
            "-23345850016.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Descenso del gradiente\n",
        "\n",
        "Ahora escribiremos una función que realice un descenso de gradiente. La premisa básica es simple. Dado un punto de partida actualizamos los pesos actuales moviéndonos en la dirección del gradiente negativo. Recordemos que el gradiente es la dirección de *incremento* y por lo tanto el gradiente negativo es la dirección de *decrecimiento* y estamos tratando de *minimizar* una función de coste. \n",
        "\n",
        "La cantidad en la que nos movemos en la *dirección* del gradiente negativo se denomina \"stepsize\" o \"eta\". Nos detenemos cuando estamos \"suficientemente cerca\" del óptimo. Definimos esto requiriendo que la magnitud (longitud) del vector gradiente sea menor que un \" umbral de tolerancia\" fijo.\n",
        "\n",
        "Teniendo esto en cuenta, completa la siguiente función de descenso del gradiente utilizando tu función derivada anterior. Para cada paso en el descenso de gradiente actualizamos el peso de cada característica antes de calcular nuestro criterio de parada"
      ],
      "metadata": {
        "id": "-jbHLZaoolPj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from math import sqrt # recuerda que la magnitud/longitud de un vector [g[0], g[1], g[2]] es sqrt(g[0]^2 + g[1]^2 + g[2]^2)"
      ],
      "metadata": {
        "id": "TAu2Y8ueoeiY"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def regression_gradient_descent(feature_matrix, output, initial_weights, step_size, tolerance):\n",
        "    converged = False \n",
        "    weights = np.array(initial_weights)  #asegúrate que es un np array\n",
        "    while not converged:\n",
        "\n",
        "        #calcule las predicciones basadas en la feature_matrix y los pesos utilizando su función predict_output()\n",
        "        #COMPLETAR\n",
        "        predictions = predict_output(feature_matrix, weights)\n",
        "        \n",
        "        # computar los errores como predictions - output\n",
        "        errors = predictions - output\n",
        "\n",
        "        gradient_sum_squares = 0 #inicializar el gradiente sum_of_squares\n",
        "\n",
        "        for i in range(len(weights)): #iteramos sobre los pesos\n",
        "\n",
        "\n",
        "            # Recordemos que feature_matrix[:, i] es la columna de características asociada a weights[i]\n",
        "            # calcula la derivada para weights[i]:\n",
        "            #COMPLETAR\n",
        "\n",
        "            derivative = feature_derivative(errors, feature_matrix[:, i])  \n",
        "            \n",
        "            # suma el valor cuadrado de la derivada a la suma de cuadrados del gradiente (para evaluar la convergencia)\n",
        "            #COMPLETAR\n",
        "            gradient_sum_squares += (derivative**2)\n",
        "\n",
        "            # restar el stepsize multiplicado por la derivada del peso actual\n",
        "            #COMPLETAR\n",
        "            weights[i] -= (step_size * derivative)\n",
        "      \n",
        "            # calcular la raíz cuadrada de la suma de cuadrados (gradient_sum_squares) del gradiente para obtener la magnitud del gradiente:\n",
        "            gradient_magnitude = sqrt(gradient_sum_squares)\n",
        "\n",
        "            \n",
        "            \n",
        "            \n",
        "        \n",
        "        if gradient_magnitude < tolerance:\n",
        "            converged = True\n",
        "    return(weights)"
      ],
      "metadata": {
        "id": "dWM8iLY8phEd"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hay que tener en cuenta algunas cosas antes de ejecutar el descenso de gradiente. Dado que el gradiente es una suma de todos los puntos de datos e implica un producto de un error y una característica, el gradiente en sí será muy grande, ya que las características son grandes (squarefeets) y la salida es grande (price). Por lo tanto, aunque se puede esperar que la \"tolerancia\" sea pequeña, lo es sólo en relación con el tamaño de las características. \n",
        "\n",
        "Por razones similares, el stepsize será mucho menor de lo que cabría esperar, pero esto se debe a que el gradiente tiene valores muy grandes."
      ],
      "metadata": {
        "id": "To75OpyIr1sX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ejecutando el Descenso Gradiente como Regresión Simple\n",
        "\n",
        "Aunque el descenso del gradiente está diseñado para la regresión múltiple, ya que la constante es ahora una característica, podemos utilizar la función de descenso del gradiente para estimar los parámetros en la regresión simple en **sqft**. La siguiente celda establece la feature_matriz, el output, los pesos iniciales y el 'stepsize' para el primer modelo:"
      ],
      "metadata": {
        "id": "56Rh1aadsFh2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Vamos a testear el descenso del gradiente\n",
        "simple_features = ['sqft_living']\n",
        "my_output = 'price'\n",
        "(simple_feature_matrix, output) = get_numpy_data(df_train, simple_features, my_output)\n",
        "initial_weights = np.array([-47000., 1.])\n",
        "step_size = 7e-12\n",
        "tolerance = 2.5e7"
      ],
      "metadata": {
        "id": "TzaDdKJ0romB"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A continuación, ejecute el descenso del gradiente con los parámetros anteriores."
      ],
      "metadata": {
        "id": "vvck7DpmsoCD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#COMPLETAR\n",
        "test_weight = regression_gradient_descent(simple_feature_matrix, output, initial_weights, step_size, tolerance)\n",
        "print(test_weight)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hy2SmEiYshiX",
        "outputId": "fa9440a9-7a1c-4451-d8d1-c653b9133e95"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-46999.88716555    281.91211918]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Utiliza los pesos recién estimados y la función predict_output() para calcular las predicciones sobre todos los datos de TEST (primero tendrás que crear un numpy array con el test de feature_matrix y test_output primero"
      ],
      "metadata": {
        "id": "apasjg7Otg8o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "simple_features = ['sqft_living']\n",
        "my_output = 'price'\n",
        "(test_simple_feature_matrix, test_output) = get_numpy_data(df_test, simple_features, my_output)\n"
      ],
      "metadata": {
        "id": "LNgs4s4Qsvwa"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_predictions = predict_output(test_simple_feature_matrix, test_weight)\n",
        "print(\"Example:\",test_predictions[0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JK8ds9u2t8n0",
        "outputId": "644ccdd5-0df9-418f-9d40-21b92f439994"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example: 356134.4432550024\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora que tiene las predicciones sobre los datos de test, calcule el RSS sobre el conjunto de test. Guarde este valor para compararlo más adelante. Recuerde que el RSS es la suma de los errores al cuadrado (diferencia entre la predicción y el output).\n",
        "\n"
      ],
      "metadata": {
        "id": "D2OwMsvIueHC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_residuals = test_output - test_predictions\n",
        "\n",
        "test_RSS = (test_residuals * test_residuals).sum()\n",
        "print(test_RSS)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sCUMKR01uZVT",
        "outputId": "b5e955b5-1383-4cde-acfb-0ab39937f6b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "275400044902128.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ejecutar una regresión múltiple\n",
        "\n",
        "Ahora utilizaremos más de una característica real. Utilice el siguiente \n",
        "código para producir los pesos  (weights) de un segundo modelo con los siguientes parámetros:"
      ],
      "metadata": {
        "id": "ubZL6gi5uvM-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_features = ['sqft_living', 'sqft_living15'] # sqft_living15 es la media de pies cuadrados de los 15 vecinos más cercanos.\n",
        "my_output = 'price'\n",
        "(feature_matrix, multi_output) = get_numpy_data(df_train, model_features, my_output)\n",
        "initial_weights = np.array([-100000., 1., 1.])\n",
        "step_size = 4e-12\n",
        "tolerance = 1e9\n"
      ],
      "metadata": {
        "id": "JdEpnHVzum9y"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Utilice los parámetros anteriores para estimar los pesos del modelo. GUARDA LOS VALORES EN UNA VARIABLE."
      ],
      "metadata": {
        "id": "es3Fa67lzZQz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "multi_weights = regression_gradient_descent(feature_matrix, multi_output, initial_weights, step_size, tolerance)\n",
        "print(multi_weights)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R3HlpgmBzcyh",
        "outputId": "0b9a4921-c9a7-4ddb-cc01-3d61c83050bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-9.99999688e+04  2.45072603e+02  6.52795267e+01]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "multi_weights"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ht-2W_f8zgVj",
        "outputId": "fcc18ca4-34a1-4bea-8ca7-7d66c29be09b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-9.99999688e+04,  2.45072603e+02,  6.52795267e+01])"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Usa tus pesos recién estimados y la función predict_output para calcular las predicciones en los datos de TEST. No olvides crear primero una matriz numpy para estas características del conjunto de prueba."
      ],
      "metadata": {
        "id": "wT4uvTbSz7MQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(test_multi_feature_matrix, multi_output) = get_numpy_data(df_test, model_features, my_output)\n",
        "multi_predictions = predict_output(test_multi_feature_matrix, multi_weights)\n",
        "\n",
        "print(multi_predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LjwH6RzmzrSO",
        "outputId": "31f1a978-eb8a-47cb-c54f-2a6d6d29ba60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[366651.41162949 762662.39850726 386312.09557541 ... 682087.39916306\n",
            " 585579.27901327 216559.20391786]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Pregunta: ¿Cuál es el precio previsto para la primera vivienda del conjunto de datos de PRUEBA para el modelo 2 (redondee al dólar más próximo)?**"
      ],
      "metadata": {
        "id": "P0VhEZyl0J3A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print (multi_predictions[0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A7aXv7vl0BCW",
        "outputId": "216b4a46-1720-4eae-880c-f604a4519075"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "366651.4116294939\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "¿Cuál es el precio real de la primera vivienda del conjunto de datos de prueba?"
      ],
      "metadata": {
        "id": "SxmV5yxC0Uoz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_test['price'][0]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vtZa043d0QXh",
        "outputId": "bcf8bde6-858d-4649-9fe4-f4f2f4458aa8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "310000.0"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pregunta: ¿Qué estimación se acercó más al precio real de la 1ª casa en el conjunto de datos de TEST, el modelo 1 o el modelo 2?\n",
        "\n",
        "Utilice ahora sus predicciones y el OUTPUT para calcular el RSS del modelo 2 en los datos de PRUEBA."
      ],
      "metadata": {
        "id": "uPlljKNR0k9C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print ('la predicción del primer modelo es 356134 $ y la del segundo modelo es 3666651 $')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1zKaF-0-0hWX",
        "outputId": "13f77149-6728-4e90-91b4-fd87710da678"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "la predicción del primer modelo es 356134 $ y la del segundo modelo es 3666651 $\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pregunta: ¿Qué modelo (1 ó 2) tiene el RSS más bajo en todos los datos de TEST?"
      ],
      "metadata": {
        "id": "dg3iLbEn1AAc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('RSS del primer modelo es 2,75400047593e+14 y RSS del segundo modelo es 2,70263446465e+14\".')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "13vVk7qw0Wfh",
        "outputId": "b87d6057-e1ea-4572-a5f9-42e8a51b1449"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RSS del primer modelo es 2,75400047593e+14 y RSS del segundo modelo es 2,70263446465e+14\".\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ic1HT7dT1Rz6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}