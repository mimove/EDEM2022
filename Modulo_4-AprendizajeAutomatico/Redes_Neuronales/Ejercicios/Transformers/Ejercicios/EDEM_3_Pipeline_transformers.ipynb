{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M3va2amFiOlI"
      },
      "source": [
        "# Introducci√≥n a la librer√≠a ü§ó Transformers\n",
        "Este notebook es una demostraci√≥n de las tareas que se pueden realizar con la librer√≠a ü§ó *transformers* de [Hugging face](https://huggingface.co)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ifZpl_EQit3X"
      },
      "outputs": [],
      "source": [
        "#instalamos la librer√≠a\n",
        "!pip install transformers[sentencepiece]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rw763hjWjHjO"
      },
      "source": [
        "## Uso de tareas con `pipeline`\n",
        "La manera m√°s directa de usar una tarea pre-entrenada en los modelos transformers de Hugging Face es mediante un `pipeline`. La librer√≠a Transformers tiene tareas pre-entrenadas para:\n",
        "- Sentiment analysis: is a text positive or negative?\n",
        "- Text generation (in English): provide a prompt and the model will generate what follows.\n",
        "- Name entity recognition (NER): in an input sentence, label each word with the entity it represents (person, place,\n",
        "  etc.)\n",
        "- Question answering: provide the model with some context and a question, extract the answer from the context.\n",
        "- Filling masked text: given a text with masked words (e.g., replaced by `[MASK]`), fill the blanks.\n",
        "- Summarization: generate a summary of a long text.\n",
        "- Translation: translate a text in another language.\n",
        "- Feature extraction: return a tensor representation of the text.  \n",
        "\n",
        "Primero importamos la clase `pipeline` antes de poder usarla:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ddHA8PCC08ZO"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Md32CCdENHX7"
      },
      "source": [
        "### An√°lisis de sentimientos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U45nyFm-jYAD"
      },
      "outputs": [],
      "source": [
        "classifier = pipeline('sentiment-analysis')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0LIV-v9TjvPn"
      },
      "source": [
        "Una vez instanciado el modelo, el uso es casi inmediato:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DtjCnY4ojsAS"
      },
      "outputs": [],
      "source": [
        "classifier('We are very happy to show you the ü§ó Transformers library.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "diG7ZdqOdkgX"
      },
      "outputs": [],
      "source": [
        "classifier.model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eGBTPM_nLL_S"
      },
      "outputs": [],
      "source": [
        "classifier.model.config.id2label"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zBTVdB6Tj57I"
      },
      "source": [
        "Podemos elegir cualquier modelo pre-entrenado del [model hub](https://huggingface.co/models) de HugginFace. Por ejemplo el modelo `\"nlptown/bert-base-multilingual-uncased-sentiment\"` est√° pre-entrenado en varios idiomas, entre ellos el espa√±ol"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QbF1JVrsj4p1"
      },
      "outputs": [],
      "source": [
        "classifier = pipeline('sentiment-analysis', model=\"nlptown/bert-base-multilingual-uncased-sentiment\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xaicS04BdaDh"
      },
      "outputs": [],
      "source": [
        "classifier('We are very happy to show you the ü§ó Transformers library.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "24s42odmB_JQ"
      },
      "outputs": [],
      "source": [
        "classifier.model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UPTd2P4Mklhc"
      },
      "outputs": [],
      "source": [
        "classifier('Me encanta el helado de vainilla')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AUtKB_5tkuko"
      },
      "outputs": [],
      "source": [
        "classifier('I hate chocolate ice cream')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tl5-0tSWA8da"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "outputs = classifier(['Odio el helado de chocolate', 'Me encanta el helado de vainilla'])\n",
        "pd.DataFrame(outputs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9jOWmoCclJhQ"
      },
      "source": [
        "### Zero-shot classification\n",
        "Con esta tarea podemos clasificar un texto de manera no supervisada, sin necesidad de usar un conjunto de entrenamiento etiquetado."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vZbirwEik1u1"
      },
      "outputs": [],
      "source": [
        "classifier = pipeline(\"zero-shot-classification\")\n",
        "classifier(\n",
        "    \"This is a course about the Transformers library\",\n",
        "    candidate_labels=[\"business\", \"education\", \"sports\"],\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gstSPzqWlnxg"
      },
      "source": [
        "### Generaci√≥n de texto\n",
        "Usando un modelo generativo (de tipo auto-regresivo) podemos generar un texto a partir de una semilla."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o7-5KY6-lWla"
      },
      "outputs": [],
      "source": [
        "generator = pipeline(\"text-generation\")\n",
        "generator(\"In this tutorial, we will teach you how to\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "88jFbIUdGaQ7"
      },
      "outputs": [],
      "source": [
        "generator.model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KZ_2D2rul1QD"
      },
      "outputs": [],
      "source": [
        "output = generator(\"In this tutorial, we will teach you how to\", num_return_sequences=2)\n",
        "print(output[0]['generated_text'])\n",
        "print(output[1]['generated_text'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vjn_Z4denAfR"
      },
      "outputs": [],
      "source": [
        "generator = pipeline(\"text-generation\", model=\"mrm8488/spanish-gpt2\")\n",
        "generator(\"Me llamo Joan y me gusta\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z6jnFE7ONlKl"
      },
      "source": [
        "### Mask filling\n",
        "Esta tarea consiste en rellenar los huecos en medio de una frase. Esta es la tarea con la que se entrenan los modelos de lenguaje de los *transformers*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U4y-bKCFN9z8"
      },
      "outputs": [],
      "source": [
        "unmasker = pipeline(\"fill-mask\")\n",
        "unmasker(\"This course will teach you all about <mask> models.\", top_k=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6trB8N_DHuH0"
      },
      "outputs": [],
      "source": [
        "unmasker(\"I went to a japanese <mask> to eat some <mask> with cheese.\", top_k=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yQzqeHbJvvL8"
      },
      "source": [
        "### Named Entity Recognition\n",
        "En esta tarea se etiqueta cada *token* seg√∫n su pertenencia a una entidad."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8tOn5TM2vs0s"
      },
      "outputs": [],
      "source": [
        "ner = pipeline(\"ner\", aggregation_strategy=\"simple\")\n",
        "outputs = ner(\"My name is Sylvain and I work at Hugging Face in Brooklyn.\")\n",
        "pd.DataFrame(outputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TURfU5E1zL0x"
      },
      "outputs": [],
      "source": [
        "# con aggregation_strategy=\"none\" (default) muestra la etiqueta de cada token con un esquema B-I-O\n",
        "ner = pipeline(\"ner\", aggregation_strategy=\"none\")\n",
        "outputs = ner(\"My name is Sylvain and I work at Hugging Face in Brooklyn.\")\n",
        "pd.DataFrame(outputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tf4L6CCxIe4Q"
      },
      "outputs": [],
      "source": [
        "ner.model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rfSy9GpIwMqS"
      },
      "source": [
        "### Sistemas de respuesta autom√°tica (question answering)\n",
        "Esta tarea consiste en responder una pregunta a partir de un contexto."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V7bxHVxTwFCS"
      },
      "outputs": [],
      "source": [
        "question_answerer = pipeline(\"question-answering\")\n",
        "context = r\"\"\"\n",
        "Joan lives in New York. His friend Antonio lives in Brussels.\n",
        "\"\"\"\n",
        "question_answerer(\n",
        "    question=\"Where does Joan live?\",\n",
        "    context=context\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "87KU4rJbKDUS"
      },
      "outputs": [],
      "source": [
        "context[15:23]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c--r7n2ldGiz"
      },
      "outputs": [],
      "source": [
        "question_answerer.model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jrH7LYQqy4LQ"
      },
      "source": [
        "### Generaci√≥n de res√∫menes (*summarization*)\n",
        "Esta tarea consiste en generar un resumen corto (abstractivo) a partir de un texto."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eR7Vfh-ByipN"
      },
      "outputs": [],
      "source": [
        "summarizer = pipeline(\"summarization\")\n",
        "summarizer(\"\"\"\n",
        "    America has changed dramatically during recent years. Not only has the number of \n",
        "    graduates in traditional engineering disciplines such as mechanical, civil, \n",
        "    electrical, chemical, and aeronautical engineering declined, but in most of \n",
        "    the premier American universities engineering curricula now concentrate on \n",
        "    and encourage largely the study of engineering science. As a result, there \n",
        "    are declining offerings in engineering subjects dealing with infrastructure, \n",
        "    the environment, and related issues, and greater concentration on high \n",
        "    technology subjects, largely supporting increasingly complex scientific \n",
        "    developments. While the latter is important, it should not be at the expense \n",
        "    of more traditional engineering.\n",
        "\n",
        "    Rapidly developing economies such as China and India, as well as other \n",
        "    industrial countries in Europe and Asia, continue to encourage and advance \n",
        "    the teaching of engineering. Both China and India, respectively, graduate \n",
        "    six and eight times as many traditional engineers as does the United States. \n",
        "    Other industrial countries at minimum maintain their output, while America \n",
        "    suffers an increasingly serious decline in the number of engineering graduates \n",
        "    and a lack of well-educated engineers.\n",
        "\"\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LC_qtAIT0dSO"
      },
      "source": [
        "### Traducci√≥n de texto\n",
        "Se puede usar el modelo por defecto especificando el par de idiomas en el nombre de la tarea, o podemos usar un modelo espec√≠fico del [model hub](https://huggingface.co/models)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AhCi4UIGzf_B"
      },
      "outputs": [],
      "source": [
        "translator = pipeline(\"translation\", model=\"Helsinki-NLP/opus-mt-es-en\")\n",
        "translator(\"Me llamo Joan y soy profesor de universidad.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zfa9ww7aJMV3"
      },
      "outputs": [],
      "source": [
        "translator.model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0yoTvuoDvVkS"
      },
      "source": [
        "### *Feature extraction*\n",
        "El modelo devuelve la representaci√≥n vectorial (embeddings) de la √∫ltima capa para cada token (`last_hidden_states`)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rwupo4DFvhRi"
      },
      "outputs": [],
      "source": [
        "extractor = pipeline(model=\"bert-base-uncased\", task=\"feature-extraction\")\n",
        "sentence = \"the BERT tokenizer was created with a WordPiece model.\"\n",
        "result = extractor(sentence, return_tensors=True)\n",
        "result.shape  # This is a tensor of shape [1, sequence_lenth, hidden_dimension] representing the input string."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DjmyxT5JKwtj"
      },
      "outputs": [],
      "source": [
        "result = extractor(sentence, return_tensors=False)\n",
        "type(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bb4TQN4JK9DZ"
      },
      "outputs": [],
      "source": [
        "len(result[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x4qKwiaPLElZ"
      },
      "outputs": [],
      "source": [
        "len(result[0][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TpabF9OFKVzO"
      },
      "outputs": [],
      "source": [
        "extractor.model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "McL5nsx_wVmn"
      },
      "source": [
        "La longitud viene dada por el n¬∫ de tokens, no de palabras, a√±adiendo los tokens especiales `[CLS]` y `[SEP]`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bkA9Ya3EwaMZ"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "output = tokenizer(sentence)\n",
        "print(output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eDtoAwMlxB0q"
      },
      "outputs": [],
      "source": [
        "print(len(output.input_ids)) #n¬∫ de tokens\n",
        "print(len(sentence.split())) #n¬∫ de palabras"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenizer.convert_ids_to_tokens(output.input_ids))"
      ],
      "metadata": {
        "id": "43ogOt5zhFqR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(sentence.split())"
      ],
      "metadata": {
        "id": "Kv7YEVSnhSLz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RTT5QmMrOXKc"
      },
      "source": [
        "## Sesgo de los modelos\n",
        "Los modelos de lenguaje de los *transformers* se han entrenado con grandes cantidades de texto no supervisado, mayoritariamente obtenido de Internet. Por tanto, puede tener sesgos (racismo, sesgo de g√©nero, etc.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QqtqsSFkO0L5"
      },
      "outputs": [],
      "source": [
        "unmasker = pipeline(\"fill-mask\", model=\"bert-base-uncased\")\n",
        "result = unmasker(\"This man works as a [MASK].\")\n",
        "print([r[\"token_str\"] for r in result])\n",
        "\n",
        "result = unmasker(\"This woman works as a [MASK].\")\n",
        "print([r[\"token_str\"] for r in result])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k3VEvh5-bU1G"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}