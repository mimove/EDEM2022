{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u9Y-drgrEm9W"
      },
      "source": [
        "# Uso de transformers con las `AutoClasses` de Hugging Face\n",
        "Las clases `AutoClasses` nos permiten cargar la configuraci√≥n, tokenizado y modelo de una arquitectura transformer concreta para distintas tareas de texto.  \n",
        ">AutoClasses are here to do this job for you so that you automatically retrieve the relevant model given the name/path to the pretrained weights/config/vocabulary.\n",
        ">Instantiating one of AutoConfig, AutoModel, and AutoTokenizer will directly create a class of the relevant architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iBFQSa4PEnwK"
      },
      "outputs": [],
      "source": [
        "#instalamos la librer√≠a\n",
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vAmNUIvjEm9a"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoConfig, AutoTokenizer, AutoModel"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pCbz0ciyEm9b"
      },
      "source": [
        "Definimos un modelo (`checkpoint`) de una arquitectura concreta a cargar. Los posible modelos est√°n listados en https://huggingface.co/docs/transformers/v4.29.1/en/model_doc/auto#transformers.AutoConfig.from_pretrained  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AaDPIznvEm9b"
      },
      "outputs": [],
      "source": [
        "checkpoint = 'bert-base-cased'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XwbFiPXwEm9c"
      },
      "source": [
        "Cargamos el tokenizador espec√≠fico"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9XFSqg60Em9c"
      },
      "outputs": [],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
        "\n",
        "tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XiSFSwGa6ZPb"
      },
      "outputs": [],
      "source": [
        "input = tokenizer(\"I like the Transformers library\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vgjKHhD86dVJ"
      },
      "outputs": [],
      "source": [
        "print(input)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "roSEbE_DEm9d"
      },
      "source": [
        "Cargamos la configuraci√≥n por defecto del modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xQyHZSnDEm9d"
      },
      "outputs": [],
      "source": [
        "config = AutoConfig.from_pretrained(checkpoint)\n",
        "\n",
        "config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UIXaS_lDEm9d"
      },
      "outputs": [],
      "source": [
        "[attr for attr in dir(config) if not attr.startswith('__')]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hsSbmVtSEm9e"
      },
      "source": [
        "Podemos cambiar algunos par√°metros de la configuraci√≥n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r9xMgCAREm9e"
      },
      "outputs": [],
      "source": [
        "config.output_hidden_states = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6lJuqNi0Em9e"
      },
      "source": [
        "Cargamos un modelo base (head-less)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g_TV4ytMEm9e"
      },
      "outputs": [],
      "source": [
        "modelo = AutoModel.from_pretrained(checkpoint, config=config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i8cA_E5oFhjO"
      },
      "outputs": [],
      "source": [
        "modelo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rr567HuuTJcL"
      },
      "source": [
        "Podemos ver el detalle de cada capa con su estructura PyTorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wHfAFJyBTJcL"
      },
      "outputs": [],
      "source": [
        "!pip install torchinfo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wHyk_AkQTJcL"
      },
      "outputs": [],
      "source": [
        "from torchinfo import summary\n",
        "summary(modelo)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YGyoyh76TJcL"
      },
      "source": [
        "La entrada a los modelos transformers es el texto tokenizado con el vectorizador correspondiente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r0pB9AJc7P0T"
      },
      "outputs": [],
      "source": [
        "inputs = tokenizer(\"Hello, my dog is cute\", return_tensors=\"pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PyQKmg8reL_V"
      },
      "outputs": [],
      "source": [
        "inputs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qFR_fNOkEm9f"
      },
      "source": [
        "Los modelos gen√©ricos devuelve la √∫ltima capa de salida del ENCODER (`last_hidden_states`)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v5U_wpeDEm9f"
      },
      "outputs": [],
      "source": [
        "output = modelo(**inputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2vDJ5KvL8qMj"
      },
      "outputs": [],
      "source": [
        "output.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ig_L-r5B8uZi"
      },
      "outputs": [],
      "source": [
        "output.last_hidden_state.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GpIzNJ88TJcN"
      },
      "source": [
        "Adicionalmente el modelo BERT tambi√©n devuelve un embedding de documento en la salida `pooler_output`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OmULLfiyTJcN"
      },
      "source": [
        ">`pooler_output` contains a \"representation\" of each sequence in the batch. What it basically does is take the hidden representation of the `[CLS]` token of each sequence in the batch, and then run that through the BertPooler nn.Module. This consists of a linear layer followed by a Tanh activation function. The weights of this linear layer are already pretrained on the next sentence prediction task"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sIpOxip881at"
      },
      "outputs": [],
      "source": [
        "output.pooler_output.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8YWZ7QtxTJcN"
      },
      "source": [
        "Tambi√©n se puede acceder a todas las representaciones de las capas intermedias del ENCODER (si en la configuraci√≥n el par√°metro `'config.output_hidden_states'` est√° a `True`):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "meeRneGn88Z9"
      },
      "outputs": [],
      "source": [
        "len(output.hidden_states)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-oL4mPk2ewUz"
      },
      "outputs": [],
      "source": [
        "output.hidden_states[0].shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GjlFEbCqEm9g"
      },
      "source": [
        "## Modelos para una tarea espec√≠fica\n",
        "Tambi√©n podemos cargar la arquitectura (HEAD) para una tarea del lenguaje determinada. Existen las siguientes tareas:  https://huggingface.co/docs/transformers/v4.29.1/en/model_doc/auto#natural-language-processing\n",
        "### Clasificaci√≥n de textos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wve0gBGAEm9g"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForSequenceClassification\n",
        "\n",
        "modelo = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YPPQZyB0FlcQ"
      },
      "outputs": [],
      "source": [
        "modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ess1ePLeEm9g"
      },
      "outputs": [],
      "source": [
        "output = modelo(**inputs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EwybHoHITJcP"
      },
      "source": [
        "En este caso el modelo devuelve las probabilidades (sin normalizar) de la capa densa de salida (n¬∫ de salidas igual al n¬∫ de clases definidas)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g7HT61_T9Uhe"
      },
      "outputs": [],
      "source": [
        "output.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qJvAOHVm9Ype"
      },
      "outputs": [],
      "source": [
        "output.logits.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uPvXHvWqgiz5"
      },
      "outputs": [],
      "source": [
        "output.logits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RTSLrRZjTJcP"
      },
      "source": [
        "### Clasificaci√≥n de tokens\n",
        "P. ej. *Name Entity Recognition*, NER"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xm_8qwzAEm9g"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForTokenClassification\n",
        "\n",
        "id2label = {\n",
        "    0: \"O\",\n",
        "    1: \"B-corporation\",\n",
        "    2: \"I-corporation\",\n",
        "    3: \"B-creative-work\",\n",
        "    4: \"I-creative-work\",\n",
        "    5: \"B-group\",\n",
        "    6: \"I-group\",\n",
        "    7: \"B-location\",\n",
        "    8: \"I-location\",\n",
        "    9: \"B-person\",\n",
        "    10: \"I-person\",\n",
        "    11: \"B-product\",\n",
        "    12: \"I-product\",\n",
        "}\n",
        "label2id = {\n",
        "    \"O\": 0,\n",
        "    \"B-corporation\": 1,\n",
        "    \"I-corporation\": 2,\n",
        "    \"B-creative-work\": 3,\n",
        "    \"I-creative-work\": 4,\n",
        "    \"B-group\": 5,\n",
        "    \"I-group\": 6,\n",
        "    \"B-location\": 7,\n",
        "    \"I-location\": 8,\n",
        "    \"B-person\": 9,\n",
        "    \"I-person\": 10,\n",
        "    \"B-product\": 11,\n",
        "    \"I-product\": 12,\n",
        "}\n",
        "\n",
        "modelo = AutoModelForTokenClassification.from_pretrained(checkpoint, num_labels=13, id2label=id2label, label2id=label2id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9-HLkkiHEm9h"
      },
      "outputs": [],
      "source": [
        "modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VUSVsA5AiLQf"
      },
      "outputs": [],
      "source": [
        "inputs = tokenizer([\"I like icecream\", \"I do not like brocolli\"], padding=True, return_tensors=\"pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f9INqcRvicTi"
      },
      "outputs": [],
      "source": [
        "inputs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7umUN7sxTJcQ"
      },
      "source": [
        "### Ejercicio\n",
        "Calcula la salida del modelo sobre los documentos de entrada anteriores e interpreta el tama√±o del tensor de salida."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZY-4f21A9njE"
      },
      "outputs": [],
      "source": [
        "#Soluci√≥n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q__APJyZTJcS"
      },
      "source": [
        "## Modelos ajustados a una tarea\n",
        "Podemos hacer uso de modelos ya ajustados (*fine-tuned*) a una tarea con un dataset espec√≠fico para hacer inferencia en la misma tarea.\n",
        "Para eso, tenemos que cargar el modelo elegido y pasarle como entrada el texto tokenizado con su vectorizador correspondiente"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NsHSrL0RTJcS"
      },
      "source": [
        "### Uso de los modelos ajustados en inferencia\n",
        "Para usar estos modelos en nuestro flujo de trabajo (p. ej. como un modelo de `tensorflow.keras`) lo necesitamos cargar junto a su funci√≥n de tokenizado espec√≠fica.  \n",
        "Por ejemplo, para un modelo de an√°lisis de sentimientos:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "91CpOUorTJcS"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, TFAutoModelForSequenceClassification, AutoConfig\n",
        "\n",
        "nombre_modelo = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
        "config = AutoConfig.from_pretrained(nombre_modelo)\n",
        "config.output_hidden_states = True\n",
        "tf_model = TFAutoModelForSequenceClassification.from_pretrained(nombre_modelo, config=config)\n",
        "tokenizer = AutoTokenizer.from_pretrained(nombre_modelo)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kHsBZ0RuTJcS"
      },
      "outputs": [],
      "source": [
        "tf_model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5oVSWblkTJcS"
      },
      "source": [
        "Para usar el modelo, primero convertimos la entrada en tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6XXl34mSTJcS"
      },
      "outputs": [],
      "source": [
        "docs = [\"We are very happy to show you the ü§ó Transformers library.\", \"We hope you don't hate it.\"]\n",
        "\n",
        "tf_batch = tokenizer(\n",
        "    docs,\n",
        "    padding=True,\n",
        "    truncation=True,\n",
        "    max_length=512,\n",
        "    return_tensors=\"tf\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Ra60tIJTJcT"
      },
      "source": [
        "`tf_batch` genera un diccionario con `'inputs_ids'` y `'attention_mask'` para cada texto de entrada."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Tgu3lZlTJcT"
      },
      "outputs": [],
      "source": [
        "for key, value in tf_batch.items():\n",
        "    print(f\"{key}: {value.numpy().tolist()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kkqUmzpNTJcT"
      },
      "outputs": [],
      "source": [
        "\n",
        "print(tokenizer.convert_ids_to_tokens(tf_batch['input_ids'][0]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YEmWb-Q3TJcT"
      },
      "source": [
        "Aplicamos el modelo, que devuelve los `logits` de la √∫ltima capa y las salidas de cada capa intermedia (*embeddings*)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OPo6ruY-TJcU"
      },
      "outputs": [],
      "source": [
        "tf_outputs = tf_model(tf_batch)\n",
        "tf_outputs.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fbpqH1dYTJcU"
      },
      "outputs": [],
      "source": [
        "len(tf_outputs.hidden_states) #N¬∫ de capas internas del transformer (embedding + 6 capas atenci√≥n)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bqKWDqrnTJcU"
      },
      "outputs": [],
      "source": [
        "tf_outputs.hidden_states[0].shape #embeddings de salida de cada capa (n¬™ muestras, n¬∫ tokens, n¬∫ dimensiones)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7qPstAv7TJcV"
      },
      "outputs": [],
      "source": [
        "tf_outputs.logits #salida del modelo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EKgG23X-TJcV"
      },
      "source": [
        "Aplicamos la funci√≥n de activaci√≥n Softmax para obtener las probabilidades normalizadas de cada clase (negativo, positivo) a partir de los logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7ekJa9ZYTJcV"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "predictions = tf.nn.softmax(tf_outputs.logits, axis=-1)\n",
        "print(predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EE1qlv6CTJcV"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "pred_class = np.argmax(predictions, axis=1)\n",
        "pred_class"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "[tf_model.config.id2label[c] for c in pred_class]"
      ],
      "metadata": {
        "id": "86xrH6EsUZK7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wgnAQ9SOTJcW"
      },
      "source": [
        "### Inferencia con `PyTorch`\n",
        "Tambi√©n podemos cargar los modelos en `PyTorch`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4BSyVAgVTJcW"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForSequenceClassification\n",
        "\n",
        "config = AutoConfig.from_pretrained(nombre_modelo)\n",
        "config.output_hidden_states = True\n",
        "model = AutoModelForSequenceClassification.from_pretrained(nombre_modelo, config=config)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VWcQWOxDTJcW"
      },
      "outputs": [],
      "source": [
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AkxedlnvTJcW"
      },
      "outputs": [],
      "source": [
        "batch = tokenizer(\n",
        "    docs,\n",
        "    padding=True,\n",
        "    truncation=True,\n",
        "    max_length=512,\n",
        "    return_tensors=\"pt\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2-uziveETJcX"
      },
      "outputs": [],
      "source": [
        "batch.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CIV1oBkMTJcX"
      },
      "outputs": [],
      "source": [
        "batch.input_ids #ahora los arrays son tensores de pyTorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jnMOvfs3TJcX"
      },
      "outputs": [],
      "source": [
        "outputs = model(**batch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uFKo6_0ATJcX"
      },
      "outputs": [],
      "source": [
        "outputs.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hfAucAjbTJcX"
      },
      "outputs": [],
      "source": [
        "outputs.logits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2hml6JJ4TJcX"
      },
      "source": [
        "Convertimos las probabilidades *logits* a probabilidades normalizadas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2yG4Q69TTJcY"
      },
      "outputs": [],
      "source": [
        "outputs.logits.softmax(dim=-1).tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j2sJv_R6TJcY"
      },
      "outputs": [],
      "source": [
        "outputs.logits.softmax(dim=-1).argmax(dim=-1)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "transformers",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}