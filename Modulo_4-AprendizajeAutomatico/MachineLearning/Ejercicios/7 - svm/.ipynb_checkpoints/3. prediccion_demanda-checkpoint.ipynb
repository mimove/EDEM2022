{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicción de demanda con SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Libraries\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import pandas as pd \n",
    "\n",
    "\n",
    "from sklearn.preprocessing import scale\n",
    "import timeit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lectura de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **ant**: antelación hasta el vuelo.\n",
    "\n",
    "- **ruta**: trayecto de ida y vuelta ordenado alfabéticamente.\n",
    "        \n",
    "- **aeropuerto_origen**: aeropuerto donde despega el avión.\n",
    "\n",
    "- **aeropuerto_destino**: aeropuerto donde aterriza el avión.\n",
    "    \n",
    "- **fecha_salida**: fecha de despegue del avión.\n",
    "    \n",
    "- **num_vuelo_operador**: identificador de número de vuelo.\n",
    "\n",
    "- **month**: mes de vuelo.\n",
    "\n",
    "- **weekday**: día de la semana de vuelo.\n",
    "    \n",
    "- **timezone**: franja horaria de vuelo.\n",
    "    \n",
    "- **year**: año de vuelo.\n",
    "    \n",
    "- **capacidad**: número máximo de pax en cada vuelo, puede variar en cada vuelo.\n",
    "    \n",
    "- **demand**: billetes vendidos en cada vuelo.\n",
    "    \n",
    "- **first**: código del principal competidor de la ruta del vuelo.\n",
    "    \n",
    "- **second**: código del segundo competidor de la ruta del vuelo.\n",
    "    \n",
    "- **first_ratio**: \n",
    "    \n",
    "- **second_ratio**:\n",
    "\n",
    "- **hit**:\n",
    "\n",
    "- **first_weight**: peso de importancia del primer competidor en la ruta del vuelo respecto a I2.\n",
    "\n",
    "- **second_weight**: peso de importancia del segundo competidor en la ruta del vuelo respecto a I2.\n",
    "\n",
    "- **global_first_weight**: \n",
    "\n",
    "- **global_second_weight**: \n",
    "\n",
    "- **first_p**:\n",
    "\n",
    "- **second_p**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ant</th>\n",
       "      <th>ruta</th>\n",
       "      <th>aeropuerto_origen</th>\n",
       "      <th>aeropuerto_destino</th>\n",
       "      <th>fecha_salida</th>\n",
       "      <th>num_vuelo_operador</th>\n",
       "      <th>month</th>\n",
       "      <th>weekday</th>\n",
       "      <th>timezone</th>\n",
       "      <th>year</th>\n",
       "      <th>...</th>\n",
       "      <th>second</th>\n",
       "      <th>first_ratio</th>\n",
       "      <th>second_ratio</th>\n",
       "      <th>hit</th>\n",
       "      <th>first_weight</th>\n",
       "      <th>second_weight</th>\n",
       "      <th>global_first_ratio</th>\n",
       "      <th>global_second_ratio</th>\n",
       "      <th>first_p</th>\n",
       "      <th>second_p</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>ACEMAD</td>\n",
       "      <td>ACE</td>\n",
       "      <td>MAD</td>\n",
       "      <td>2017-02-02</td>\n",
       "      <td>3857</td>\n",
       "      <td>2</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>Mediodia</td>\n",
       "      <td>2017</td>\n",
       "      <td>...</td>\n",
       "      <td>UX</td>\n",
       "      <td>3.140340</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.520623</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.623683</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>ACEMAD</td>\n",
       "      <td>ACE</td>\n",
       "      <td>MAD</td>\n",
       "      <td>2017-02-03</td>\n",
       "      <td>3857</td>\n",
       "      <td>2</td>\n",
       "      <td>Friday</td>\n",
       "      <td>Mediodia</td>\n",
       "      <td>2017</td>\n",
       "      <td>...</td>\n",
       "      <td>UX</td>\n",
       "      <td>3.610000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.210075</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.846071</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11</td>\n",
       "      <td>ACEMAD</td>\n",
       "      <td>ACE</td>\n",
       "      <td>MAD</td>\n",
       "      <td>2017-02-04</td>\n",
       "      <td>3857</td>\n",
       "      <td>2</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>Mediodia</td>\n",
       "      <td>2017</td>\n",
       "      <td>...</td>\n",
       "      <td>UX</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.252252</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.595346</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.981601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>ACEMAD</td>\n",
       "      <td>ACE</td>\n",
       "      <td>MAD</td>\n",
       "      <td>2017-02-05</td>\n",
       "      <td>3857</td>\n",
       "      <td>2</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>Mediodia</td>\n",
       "      <td>2017</td>\n",
       "      <td>...</td>\n",
       "      <td>UX</td>\n",
       "      <td>3.094286</td>\n",
       "      <td>3.252252</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.485467</td>\n",
       "      <td>0.658558</td>\n",
       "      <td>0.955942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>ACEMAD</td>\n",
       "      <td>ACE</td>\n",
       "      <td>MAD</td>\n",
       "      <td>2017-02-06</td>\n",
       "      <td>3857</td>\n",
       "      <td>2</td>\n",
       "      <td>Monday</td>\n",
       "      <td>Mediodia</td>\n",
       "      <td>2017</td>\n",
       "      <td>...</td>\n",
       "      <td>UX</td>\n",
       "      <td>2.022857</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.648854</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.387667</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ant    ruta aeropuerto_origen aeropuerto_destino fecha_salida  \\\n",
       "0   11  ACEMAD               ACE                MAD   2017-02-02   \n",
       "1   11  ACEMAD               ACE                MAD   2017-02-03   \n",
       "2   11  ACEMAD               ACE                MAD   2017-02-04   \n",
       "3   11  ACEMAD               ACE                MAD   2017-02-05   \n",
       "4   11  ACEMAD               ACE                MAD   2017-02-06   \n",
       "\n",
       "   num_vuelo_operador  month   weekday  timezone  year  ...  second  \\\n",
       "0                3857      2  Thursday  Mediodia  2017  ...      UX   \n",
       "1                3857      2    Friday  Mediodia  2017  ...      UX   \n",
       "2                3857      2  Saturday  Mediodia  2017  ...      UX   \n",
       "3                3857      2    Sunday  Mediodia  2017  ...      UX   \n",
       "4                3857      2    Monday  Mediodia  2017  ...      UX   \n",
       "\n",
       "   first_ratio second_ratio hit first_weight  second_weight  \\\n",
       "0     3.140340     0.000000   2          0.0            0.0   \n",
       "1     3.610000     0.000000   2          0.0            0.0   \n",
       "2     0.000000     3.252252   1          0.0            1.0   \n",
       "3     3.094286     3.252252   2          0.0            1.0   \n",
       "4     2.022857     0.000000   2          0.0            0.0   \n",
       "\n",
       "   global_first_ratio  global_second_ratio   first_p  second_p  \n",
       "0            2.520623             0.000000  0.623683  0.000000  \n",
       "1            2.210075             0.000000  0.846071  0.000000  \n",
       "2            0.000000             1.595346  0.000000  0.981601  \n",
       "3            0.000000             1.485467  0.658558  0.955942  \n",
       "4            2.648854             0.000000  0.387667  0.000000  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset \n",
    "datos = pd.read_csv(\"../datasets/datos_pred_demanda.csv\", sep=';', decimal=',')\n",
    "datos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(625798, 24)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datos.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ACEMAD', 'LGWMAD', 'MADPMI', 'MADSCQ', 'MADTXL'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datos['ruta'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tenemos casi un millón de patrones correspondientes a datos de 5 rutas diferentes y 24 características o variables.\n",
    "\n",
    "Seleccionamos datos de antelacion 11 para tener un conjunto de datos asequible para esta clase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seleccionamos datos de antelacion 11 para tener un conjunto de datos asequible para esta clase\n",
    "datos = datos[datos.ant==11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34242, 24)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datos.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tratamiento de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a ordenar los datos por fecha salida para cuando escojamos el conjunto de train, validation y test se respete el eje temporal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos = datos.sort_values(by=['fecha_salida'], ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Borramos las variables que no aportan información al modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "del datos[\"num_vuelo_operador\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformar variables categoricas en numericas.\n",
    "\n",
    "1) Primero definimos las variables numericas y categoricas.\n",
    "\n",
    "2) Aplicamos one hot enconding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ruta',\n",
       " 'aeropuerto_origen',\n",
       " 'aeropuerto_destino',\n",
       " 'month',\n",
       " 'weekday',\n",
       " 'year',\n",
       " 'nombre_blackout',\n",
       " 'first',\n",
       " 'second',\n",
       " 'timezone']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_vars = ['ruta', 'aeropuerto_origen', 'aeropuerto_destino', 'month', 'weekday', 'year', \n",
    "                    'nombre_blackout', 'first', 'second', 'timezone']\n",
    "\n",
    "categorical_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['global_first_ratio',\n",
       " 'ant',\n",
       " 'fecha_salida',\n",
       " 'first_weight',\n",
       " 'global_second_ratio',\n",
       " 'first_p',\n",
       " 'hit',\n",
       " 'demand',\n",
       " 'second_p',\n",
       " 'first_ratio',\n",
       " 'second_weight',\n",
       " 'second_ratio',\n",
       " 'capacidad']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerical_vars = list(set(datos.columns) - set(categorical_vars))\n",
    "numerical_vars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One hot encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importamos la libreria que hace one hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class OneHotEncoder in module sklearn.preprocessing._encoders:\n",
      "\n",
      "class OneHotEncoder(_BaseEncoder)\n",
      " |  OneHotEncoder(*, categories='auto', drop=None, sparse=True, dtype=<class 'numpy.float64'>, handle_unknown='error')\n",
      " |  \n",
      " |  Encode categorical features as a one-hot numeric array.\n",
      " |  \n",
      " |  The input to this transformer should be an array-like of integers or\n",
      " |  strings, denoting the values taken on by categorical (discrete) features.\n",
      " |  The features are encoded using a one-hot (aka 'one-of-K' or 'dummy')\n",
      " |  encoding scheme. This creates a binary column for each category and\n",
      " |  returns a sparse matrix or dense array (depending on the ``sparse``\n",
      " |  parameter)\n",
      " |  \n",
      " |  By default, the encoder derives the categories based on the unique values\n",
      " |  in each feature. Alternatively, you can also specify the `categories`\n",
      " |  manually.\n",
      " |  \n",
      " |  This encoding is needed for feeding categorical data to many scikit-learn\n",
      " |  estimators, notably linear models and SVMs with the standard kernels.\n",
      " |  \n",
      " |  Note: a one-hot encoding of y labels should use a LabelBinarizer\n",
      " |  instead.\n",
      " |  \n",
      " |  Read more in the :ref:`User Guide <preprocessing_categorical_features>`.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  categories : 'auto' or a list of array-like, default='auto'\n",
      " |      Categories (unique values) per feature:\n",
      " |  \n",
      " |      - 'auto' : Determine categories automatically from the training data.\n",
      " |      - list : ``categories[i]`` holds the categories expected in the ith\n",
      " |        column. The passed categories should not mix strings and numeric\n",
      " |        values within a single feature, and should be sorted in case of\n",
      " |        numeric values.\n",
      " |  \n",
      " |      The used categories can be found in the ``categories_`` attribute.\n",
      " |  \n",
      " |      .. versionadded:: 0.20\n",
      " |  \n",
      " |  drop : {'first', 'if_binary'} or a array-like of shape (n_features,),             default=None\n",
      " |      Specifies a methodology to use to drop one of the categories per\n",
      " |      feature. This is useful in situations where perfectly collinear\n",
      " |      features cause problems, such as when feeding the resulting data\n",
      " |      into a neural network or an unregularized regression.\n",
      " |  \n",
      " |      However, dropping one category breaks the symmetry of the original\n",
      " |      representation and can therefore induce a bias in downstream models,\n",
      " |      for instance for penalized linear classification or regression models.\n",
      " |  \n",
      " |      - None : retain all features (the default).\n",
      " |      - 'first' : drop the first category in each feature. If only one\n",
      " |        category is present, the feature will be dropped entirely.\n",
      " |      - 'if_binary' : drop the first category in each feature with two\n",
      " |        categories. Features with 1 or more than 2 categories are\n",
      " |        left intact.\n",
      " |      - array : ``drop[i]`` is the category in feature ``X[:, i]`` that\n",
      " |        should be dropped.\n",
      " |  \n",
      " |      .. versionadded:: 0.21\n",
      " |         The parameter `drop` was added in 0.21.\n",
      " |  \n",
      " |      .. versionchanged:: 0.23\n",
      " |         The option `drop='if_binary'` was added in 0.23.\n",
      " |  \n",
      " |  sparse : bool, default=True\n",
      " |      Will return sparse matrix if set True else will return an array.\n",
      " |  \n",
      " |  dtype : number type, default=float\n",
      " |      Desired dtype of output.\n",
      " |  \n",
      " |  handle_unknown : {'error', 'ignore'}, default='error'\n",
      " |      Whether to raise an error or ignore if an unknown categorical feature\n",
      " |      is present during transform (default is to raise). When this parameter\n",
      " |      is set to 'ignore' and an unknown category is encountered during\n",
      " |      transform, the resulting one-hot encoded columns for this feature\n",
      " |      will be all zeros. In the inverse transform, an unknown category\n",
      " |      will be denoted as None.\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  categories_ : list of arrays\n",
      " |      The categories of each feature determined during fitting\n",
      " |      (in order of the features in X and corresponding with the output\n",
      " |      of ``transform``). This includes the category specified in ``drop``\n",
      " |      (if any).\n",
      " |  \n",
      " |  drop_idx_ : array of shape (n_features,)\n",
      " |      - ``drop_idx_[i]`` is the index in ``categories_[i]`` of the category\n",
      " |        to be dropped for each feature.\n",
      " |      - ``drop_idx_[i] = None`` if no category is to be dropped from the\n",
      " |        feature with index ``i``, e.g. when `drop='if_binary'` and the\n",
      " |        feature isn't binary.\n",
      " |      - ``drop_idx_ = None`` if all the transformed features will be\n",
      " |        retained.\n",
      " |  \n",
      " |      .. versionchanged:: 0.23\n",
      " |         Added the possibility to contain `None` values.\n",
      " |  \n",
      " |  See Also\n",
      " |  --------\n",
      " |  OrdinalEncoder : Performs an ordinal (integer)\n",
      " |    encoding of the categorical features.\n",
      " |  sklearn.feature_extraction.DictVectorizer : Performs a one-hot encoding of\n",
      " |    dictionary items (also handles string-valued features).\n",
      " |  sklearn.feature_extraction.FeatureHasher : Performs an approximate one-hot\n",
      " |    encoding of dictionary items or strings.\n",
      " |  LabelBinarizer : Binarizes labels in a one-vs-all\n",
      " |    fashion.\n",
      " |  MultiLabelBinarizer : Transforms between iterable of\n",
      " |    iterables and a multilabel format, e.g. a (samples x classes) binary\n",
      " |    matrix indicating the presence of a class label.\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  Given a dataset with two features, we let the encoder find the unique\n",
      " |  values per feature and transform the data to a binary one-hot encoding.\n",
      " |  \n",
      " |  >>> from sklearn.preprocessing import OneHotEncoder\n",
      " |  \n",
      " |  One can discard categories not seen during `fit`:\n",
      " |  \n",
      " |  >>> enc = OneHotEncoder(handle_unknown='ignore')\n",
      " |  >>> X = [['Male', 1], ['Female', 3], ['Female', 2]]\n",
      " |  >>> enc.fit(X)\n",
      " |  OneHotEncoder(handle_unknown='ignore')\n",
      " |  >>> enc.categories_\n",
      " |  [array(['Female', 'Male'], dtype=object), array([1, 2, 3], dtype=object)]\n",
      " |  >>> enc.transform([['Female', 1], ['Male', 4]]).toarray()\n",
      " |  array([[1., 0., 1., 0., 0.],\n",
      " |         [0., 1., 0., 0., 0.]])\n",
      " |  >>> enc.inverse_transform([[0, 1, 1, 0, 0], [0, 0, 0, 1, 0]])\n",
      " |  array([['Male', 1],\n",
      " |         [None, 2]], dtype=object)\n",
      " |  >>> enc.get_feature_names(['gender', 'group'])\n",
      " |  array(['gender_Female', 'gender_Male', 'group_1', 'group_2', 'group_3'],\n",
      " |    dtype=object)\n",
      " |  \n",
      " |  One can always drop the first column for each feature:\n",
      " |  \n",
      " |  >>> drop_enc = OneHotEncoder(drop='first').fit(X)\n",
      " |  >>> drop_enc.categories_\n",
      " |  [array(['Female', 'Male'], dtype=object), array([1, 2, 3], dtype=object)]\n",
      " |  >>> drop_enc.transform([['Female', 1], ['Male', 2]]).toarray()\n",
      " |  array([[0., 0., 0.],\n",
      " |         [1., 1., 0.]])\n",
      " |  \n",
      " |  Or drop a column for feature only having 2 categories:\n",
      " |  \n",
      " |  >>> drop_binary_enc = OneHotEncoder(drop='if_binary').fit(X)\n",
      " |  >>> drop_binary_enc.transform([['Female', 1], ['Male', 2]]).toarray()\n",
      " |  array([[0., 1., 0., 0.],\n",
      " |         [1., 0., 1., 0.]])\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      OneHotEncoder\n",
      " |      _BaseEncoder\n",
      " |      sklearn.base.TransformerMixin\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, *, categories='auto', drop=None, sparse=True, dtype=<class 'numpy.float64'>, handle_unknown='error')\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  fit(self, X, y=None)\n",
      " |      Fit OneHotEncoder to X.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape (n_samples, n_features)\n",
      " |          The data to determine the categories of each feature.\n",
      " |      \n",
      " |      y : None\n",
      " |          Ignored. This parameter exists only for compatibility with\n",
      " |          :class:`~sklearn.pipeline.Pipeline`.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self\n",
      " |  \n",
      " |  fit_transform(self, X, y=None)\n",
      " |      Fit OneHotEncoder to X, then transform X.\n",
      " |      \n",
      " |      Equivalent to fit(X).transform(X) but more convenient.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape (n_samples, n_features)\n",
      " |          The data to encode.\n",
      " |      \n",
      " |      y : None\n",
      " |          Ignored. This parameter exists only for compatibility with\n",
      " |          :class:`~sklearn.pipeline.Pipeline`.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      X_out : {ndarray, sparse matrix} of shape                 (n_samples, n_encoded_features)\n",
      " |          Transformed input. If `sparse=True`, a sparse matrix will be\n",
      " |          returned.\n",
      " |  \n",
      " |  get_feature_names(self, input_features=None)\n",
      " |      Return feature names for output features.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      input_features : list of str of shape (n_features,)\n",
      " |          String names for input features if available. By default,\n",
      " |          \"x0\", \"x1\", ... \"xn_features\" is used.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      output_feature_names : ndarray of shape (n_output_features,)\n",
      " |          Array of feature names.\n",
      " |  \n",
      " |  inverse_transform(self, X)\n",
      " |      Convert the data back to the original representation.\n",
      " |      \n",
      " |      In case unknown categories are encountered (all zeros in the\n",
      " |      one-hot encoding), ``None`` is used to represent this category.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape                 (n_samples, n_encoded_features)\n",
      " |          The transformed data.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      X_tr : ndarray of shape (n_samples, n_features)\n",
      " |          Inverse transformed array.\n",
      " |  \n",
      " |  transform(self, X)\n",
      " |      Transform X using one-hot encoding.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape (n_samples, n_features)\n",
      " |          The data to encode.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      X_out : {ndarray, sparse matrix} of shape                 (n_samples, n_encoded_features)\n",
      " |          Transformed input. If `sparse=True`, a sparse matrix will be\n",
      " |          returned.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.base.TransformerMixin:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __repr__(self, N_CHAR_MAX=700)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : bool, default=True\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : dict\n",
      " |          Parameter names mapped to their values.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |      \n",
      " |      The method works on simple estimators as well as on nested objects\n",
      " |      (such as :class:`~sklearn.pipeline.Pipeline`). The latter have\n",
      " |      parameters of the form ``<component>__<parameter>`` so that it's\n",
      " |      possible to update each component of a nested object.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      **params : dict\n",
      " |          Estimator parameters.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : estimator instance\n",
      " |          Estimator instance.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(OneHotEncoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realizamos one hot encoding de las variables categoricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe = OneHotEncoder(sparse = False)\n",
    "\n",
    "ohe_fit = ohe.fit(datos[categorical_vars])\n",
    "X_ohe = pd.DataFrame(ohe.fit_transform(datos[categorical_vars]))\n",
    "X_ohe.columns = pd.DataFrame(ohe_fit.get_feature_names())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizamos los datos iniciales y los que están con one hot encoding para ver la diferencia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ant</th>\n",
       "      <th>ruta</th>\n",
       "      <th>aeropuerto_origen</th>\n",
       "      <th>aeropuerto_destino</th>\n",
       "      <th>fecha_salida</th>\n",
       "      <th>month</th>\n",
       "      <th>weekday</th>\n",
       "      <th>timezone</th>\n",
       "      <th>year</th>\n",
       "      <th>capacidad</th>\n",
       "      <th>...</th>\n",
       "      <th>second</th>\n",
       "      <th>first_ratio</th>\n",
       "      <th>second_ratio</th>\n",
       "      <th>hit</th>\n",
       "      <th>first_weight</th>\n",
       "      <th>second_weight</th>\n",
       "      <th>global_first_ratio</th>\n",
       "      <th>global_second_ratio</th>\n",
       "      <th>first_p</th>\n",
       "      <th>second_p</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>ACEMAD</td>\n",
       "      <td>ACE</td>\n",
       "      <td>MAD</td>\n",
       "      <td>2017-02-02</td>\n",
       "      <td>2</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>Mediodia</td>\n",
       "      <td>2017</td>\n",
       "      <td>213</td>\n",
       "      <td>...</td>\n",
       "      <td>UX</td>\n",
       "      <td>3.140340</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.520623</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.623683</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29080</th>\n",
       "      <td>11</td>\n",
       "      <td>MADTXL</td>\n",
       "      <td>MAD</td>\n",
       "      <td>TXL</td>\n",
       "      <td>2017-02-02</td>\n",
       "      <td>2</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>Tarde</td>\n",
       "      <td>2017</td>\n",
       "      <td>176</td>\n",
       "      <td>...</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>2.557941</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.415747</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.640143</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6007</th>\n",
       "      <td>11</td>\n",
       "      <td>LGWMAD</td>\n",
       "      <td>MAD</td>\n",
       "      <td>LGW</td>\n",
       "      <td>2017-02-02</td>\n",
       "      <td>2</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>Matutina</td>\n",
       "      <td>2017</td>\n",
       "      <td>172</td>\n",
       "      <td>...</td>\n",
       "      <td>D8</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.339117</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.405146</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6008</th>\n",
       "      <td>11</td>\n",
       "      <td>LGWMAD</td>\n",
       "      <td>MAD</td>\n",
       "      <td>LGW</td>\n",
       "      <td>2017-02-02</td>\n",
       "      <td>2</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>Tarde_Noche</td>\n",
       "      <td>2017</td>\n",
       "      <td>176</td>\n",
       "      <td>...</td>\n",
       "      <td>D8</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.845015</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.013701</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.275469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8192</th>\n",
       "      <td>11</td>\n",
       "      <td>MADPMI</td>\n",
       "      <td>MAD</td>\n",
       "      <td>PMI</td>\n",
       "      <td>2017-02-02</td>\n",
       "      <td>2</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>Tarde</td>\n",
       "      <td>2017</td>\n",
       "      <td>174</td>\n",
       "      <td>...</td>\n",
       "      <td>UX</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.813973</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.149599</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.991889</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ant    ruta aeropuerto_origen aeropuerto_destino fecha_salida  month  \\\n",
       "0       11  ACEMAD               ACE                MAD   2017-02-02      2   \n",
       "29080   11  MADTXL               MAD                TXL   2017-02-02      2   \n",
       "6007    11  LGWMAD               MAD                LGW   2017-02-02      2   \n",
       "6008    11  LGWMAD               MAD                LGW   2017-02-02      2   \n",
       "8192    11  MADPMI               MAD                PMI   2017-02-02      2   \n",
       "\n",
       "        weekday     timezone  year  capacidad  ...   second first_ratio  \\\n",
       "0      Thursday     Mediodia  2017        213  ...       UX    3.140340   \n",
       "29080  Thursday        Tarde  2017        176  ...  UNKNOWN    2.557941   \n",
       "6007   Thursday     Matutina  2017        172  ...       D8    1.000000   \n",
       "6008   Thursday  Tarde_Noche  2017        176  ...       D8    0.000000   \n",
       "8192   Thursday        Tarde  2017        174  ...       UX    0.000000   \n",
       "\n",
       "      second_ratio hit  first_weight  second_weight  global_first_ratio  \\\n",
       "0         0.000000   2           0.0            0.0            2.520623   \n",
       "29080     0.000000   1           1.0            0.0            2.415747   \n",
       "6007      0.000000   1           1.0            0.0            1.339117   \n",
       "6008      0.845015   1           0.0            1.0            0.000000   \n",
       "8192      1.813973   1           0.0            1.0            0.000000   \n",
       "\n",
       "       global_second_ratio   first_p  second_p  \n",
       "0                 0.000000  0.623683  0.000000  \n",
       "29080             0.000000  0.640143  0.000000  \n",
       "6007              0.000000  0.405146  0.000000  \n",
       "6008              1.013701  0.000000  0.275469  \n",
       "8192              1.149599  0.000000  0.991889  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>(x0_ACEMAD,)</th>\n",
       "      <th>(x0_LGWMAD,)</th>\n",
       "      <th>(x0_MADPMI,)</th>\n",
       "      <th>(x0_MADSCQ,)</th>\n",
       "      <th>(x0_MADTXL,)</th>\n",
       "      <th>(x1_ACE,)</th>\n",
       "      <th>(x1_LGW,)</th>\n",
       "      <th>(x1_MAD,)</th>\n",
       "      <th>(x1_PMI,)</th>\n",
       "      <th>(x1_SCQ,)</th>\n",
       "      <th>...</th>\n",
       "      <th>(x8_D8,)</th>\n",
       "      <th>(x8_UNKNOWN,)</th>\n",
       "      <th>(x8_UX,)</th>\n",
       "      <th>(x9_Manana,)</th>\n",
       "      <th>(x9_Matutina,)</th>\n",
       "      <th>(x9_Mediodia,)</th>\n",
       "      <th>(x9_Noche,)</th>\n",
       "      <th>(x9_Nocturna,)</th>\n",
       "      <th>(x9_Tarde,)</th>\n",
       "      <th>(x9_Tarde_Noche,)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   (x0_ACEMAD,)  (x0_LGWMAD,)  (x0_MADPMI,)  (x0_MADSCQ,)  (x0_MADTXL,)  \\\n",
       "0           1.0           0.0           0.0           0.0           0.0   \n",
       "1           0.0           0.0           0.0           0.0           1.0   \n",
       "2           0.0           1.0           0.0           0.0           0.0   \n",
       "3           0.0           1.0           0.0           0.0           0.0   \n",
       "4           0.0           0.0           1.0           0.0           0.0   \n",
       "\n",
       "   (x1_ACE,)  (x1_LGW,)  (x1_MAD,)  (x1_PMI,)  (x1_SCQ,)  ...  (x8_D8,)  \\\n",
       "0        1.0        0.0        0.0        0.0        0.0  ...       0.0   \n",
       "1        0.0        0.0        1.0        0.0        0.0  ...       0.0   \n",
       "2        0.0        0.0        1.0        0.0        0.0  ...       1.0   \n",
       "3        0.0        0.0        1.0        0.0        0.0  ...       1.0   \n",
       "4        0.0        0.0        1.0        0.0        0.0  ...       0.0   \n",
       "\n",
       "   (x8_UNKNOWN,)  (x8_UX,)  (x9_Manana,)  (x9_Matutina,)  (x9_Mediodia,)  \\\n",
       "0            0.0       1.0           0.0             0.0             1.0   \n",
       "1            1.0       0.0           0.0             0.0             0.0   \n",
       "2            0.0       0.0           0.0             1.0             0.0   \n",
       "3            0.0       0.0           0.0             0.0             0.0   \n",
       "4            0.0       1.0           0.0             0.0             0.0   \n",
       "\n",
       "   (x9_Noche,)  (x9_Nocturna,)  (x9_Tarde,)  (x9_Tarde_Noche,)  \n",
       "0          0.0             0.0          0.0                0.0  \n",
       "1          0.0             0.0          1.0                0.0  \n",
       "2          0.0             0.0          0.0                0.0  \n",
       "3          0.0             0.0          0.0                1.0  \n",
       "4          0.0             0.0          1.0                0.0  \n",
       "\n",
       "[5 rows x 59 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_ohe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatenamos los datos categoricos con one hot enconding y los numericos para tener el dataset completo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos = pd.concat((X_ohe, datos[numerical_vars].reset_index()), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['fecha_salida'], dtype='object')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datos.columns[datos.dtypes == object]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comprobamos que ahora todos los datos son numericos menos fecha salida que lo quitaremos por ser una importante del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "fecha_salida_values = datos['fecha_salida']\n",
    "del datos['fecha_salida']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Escalado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a gurdar nuestro target, la demanda, en una variable aparte ya que el target no hace falta escalarlo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = datos['demand']\n",
    "del datos['demand']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Escalamos los datos mediante la media y la desviación típica.\n",
    "\n",
    "Este paso es muy importante en un modelo machine learning ya que si las variables tienen escalas muy diferentes el modelo dará mucho más peso a las variables con valores mas altos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../figures/tipify.png\" width=\"50%\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos_scale = pd.DataFrame(scale(datos))\n",
    "datos_scale.columns = datos.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizamos los datos iniciales y los escalados para ver la diferencia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   (x0_ACEMAD,)  (x0_LGWMAD,)  (x0_MADPMI,)  (x0_MADSCQ,)  (x0_MADTXL,)  \\\n",
      "0           1.0           0.0           0.0           0.0           0.0   \n",
      "1           0.0           0.0           0.0           0.0           1.0   \n",
      "2           0.0           1.0           0.0           0.0           0.0   \n",
      "3           0.0           1.0           0.0           0.0           0.0   \n",
      "4           0.0           0.0           1.0           0.0           0.0   \n",
      "\n",
      "   (x1_ACE,)  (x1_LGW,)  (x1_MAD,)  (x1_PMI,)  (x1_SCQ,)  ...  ant  \\\n",
      "0        1.0        0.0        0.0        0.0        0.0  ...   11   \n",
      "1        0.0        0.0        1.0        0.0        0.0  ...   11   \n",
      "2        0.0        0.0        1.0        0.0        0.0  ...   11   \n",
      "3        0.0        0.0        1.0        0.0        0.0  ...   11   \n",
      "4        0.0        0.0        1.0        0.0        0.0  ...   11   \n",
      "\n",
      "   first_weight  global_second_ratio   first_p  hit  second_p  first_ratio  \\\n",
      "0           0.0             0.000000  0.623683    2  0.000000     3.140340   \n",
      "1           1.0             0.000000  0.640143    1  0.000000     2.557941   \n",
      "2           1.0             0.000000  0.405146    1  0.000000     1.000000   \n",
      "3           0.0             1.013701  0.000000    1  0.275469     0.000000   \n",
      "4           0.0             1.149599  0.000000    1  0.991889     0.000000   \n",
      "\n",
      "   second_weight  second_ratio  capacidad  \n",
      "0            0.0      0.000000        213  \n",
      "1            0.0      0.000000        176  \n",
      "2            0.0      0.000000        172  \n",
      "3            1.0      0.845015        176  \n",
      "4            1.0      1.813973        174  \n",
      "\n",
      "[5 rows x 71 columns]\n",
      "   (x0_ACEMAD,)  (x0_LGWMAD,)  (x0_MADPMI,)  (x0_MADSCQ,)  (x0_MADTXL,)  \\\n",
      "0      2.822450     -0.382630     -0.730284     -0.596127     -0.421320   \n",
      "1     -0.354302     -0.382630     -0.730284     -0.596127      2.373494   \n",
      "2     -0.354302      2.613489     -0.730284     -0.596127     -0.421320   \n",
      "3     -0.354302      2.613489     -0.730284     -0.596127     -0.421320   \n",
      "4     -0.354302     -0.382630      1.369329     -0.596127     -0.421320   \n",
      "\n",
      "   (x1_ACE,)  (x1_LGW,)  (x1_MAD,)  (x1_PMI,)  (x1_SCQ,)  ...  ant  \\\n",
      "0   4.115476  -0.261266  -0.999008  -0.459292  -0.388377  ...  0.0   \n",
      "1  -0.242985  -0.261266   1.000993  -0.459292  -0.388377  ...  0.0   \n",
      "2  -0.242985  -0.261266   1.000993  -0.459292  -0.388377  ...  0.0   \n",
      "3  -0.242985  -0.261266   1.000993  -0.459292  -0.388377  ...  0.0   \n",
      "4  -0.242985  -0.261266   1.000993  -0.459292  -0.388377  ...  0.0   \n",
      "\n",
      "   first_weight  global_second_ratio   first_p       hit  second_p  \\\n",
      "0     -0.836621            -0.784568  0.920076  0.936178 -0.795307   \n",
      "1      1.566123            -0.784568  0.970004 -0.762095 -0.795307   \n",
      "2      1.566123            -0.784568  0.257213 -0.762095 -0.795307   \n",
      "3     -0.836621             0.781760 -0.971669 -0.762095  0.035931   \n",
      "4     -0.836621             0.991742 -0.971669 -0.762095  2.197753   \n",
      "\n",
      "   first_ratio  second_weight  second_ratio  capacidad  \n",
      "0     1.229701      -0.828474     -0.748274   2.181833  \n",
      "1     0.845664      -0.828474     -0.748274  -0.400404  \n",
      "2    -0.181651      -0.828474     -0.748274  -0.679565  \n",
      "3    -0.841056       1.584820      0.311369  -0.400404  \n",
      "4    -0.841056       1.584820      1.526437  -0.539984  \n",
      "\n",
      "[5 rows x 71 columns]\n"
     ]
    }
   ],
   "source": [
    "print(datos.head())\n",
    "print(datos_scale.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos = datos_scale\n",
    "datos['fecha_salida'] = fecha_salida_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Elección de los conjuntos de entrenamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.1 Conjunto de Validación Fijo\n",
    "\n",
    "Utilizaremos a modo de ejemplo los ratios habitualmente recomendados:\n",
    "\n",
    "• Train: 70%.\n",
    "\n",
    "• Validación: 15%.\n",
    "\n",
    "• Test: 15%.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "perc_values = [0.7, 0.15, 0.15];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos los conjuntos de train, validacion y test con el tamaño seleccionado pero de manera aleatoria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_rand, X_valtest_rand, y_train_rand, y_valtest_rand = train_test_split(datos, y, test_size=perc_values[1] + perc_values[2], random_state=1);\n",
    "\n",
    "X_val_rand, X_test_rand, y_val_rand, y_test_rand = train_test_split(X_valtest_rand, y_valtest_rand, test_size= perc_values[2] / (perc_values[1] + perc_values[2]), random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos los conjuntos de train, validacion y test con el tamaño seleccionado pero respetando el eje temporal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dimensiones de los conjuntos de train y test\n",
    "n_train = int(datos.shape[0] * perc_values[0])\n",
    "n_val = int(datos.shape[0] * perc_values[1])\n",
    "n_test = int(datos.shape[0] * perc_values[2])\n",
    "\n",
    "# selección del conjunto de train\n",
    "X_train = datos.iloc[:n_train]\n",
    "y_train = y.iloc[:n_train]\n",
    "\n",
    "# selección del conjunto de validación\n",
    "X_val = datos.iloc[(n_train):(n_train+n_val)]\n",
    "y_val = y.iloc[(n_train):(n_train+n_val)]\n",
    "\n",
    "# selección del conjunto de test\n",
    "X_test = datos.iloc[(n_train+n_val):]\n",
    "y_test = y.iloc[(n_train+n_val):]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizamos el tamaño de los conjuntos para el set aleatorio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data size = (23969, 72)\n",
      "Train target size = (23969,)\n",
      "Validation data size = (5136, 72)\n",
      "Validation target size = (5136,)\n",
      "Test data size = (5137, 72)\n",
      "Test target size = (5137,)\n"
     ]
    }
   ],
   "source": [
    "print('Train data size = ' + str(X_train_rand.shape))\n",
    "print('Train target size = ' + str(y_train_rand.shape))\n",
    "print('Validation data size = ' + str(X_val_rand.shape))\n",
    "print('Validation target size = ' + str(y_val_rand.shape))\n",
    "print('Test data size = ' + str(X_test_rand.shape))\n",
    "print('Test target size = ' + str(y_test_rand.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizamos el tamaño de los conjuntos para el set con el eje temporal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data size = (23969, 72)\n",
      "Train target size = (23969,)\n",
      "Validation data size = (5136, 72)\n",
      "Validation target size = (5136,)\n",
      "Test data size = (5137, 72)\n",
      "Test target size = (5137,)\n"
     ]
    }
   ],
   "source": [
    "print('Train data size = ' + str(X_train.shape))\n",
    "print('Train target size = ' + str(y_train.shape))\n",
    "print('Validation data size = ' + str(X_val.shape))\n",
    "print('Validation target size = ' + str(y_val.shape))\n",
    "print('Test data size = ' + str(X_test.shape))\n",
    "print('Test target size = ' + str(y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comprobamos que estos conjuntos tienen el mismo tamaño"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizamos las fecha de salida de los conjuntos para el set aleatorio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train min date data = 2017-02-02\n",
      "Train max date data = 2020-02-18\n",
      "Val min date data = 2017-02-02\n",
      "Val max date data = 2020-02-18\n",
      "Test min date data = 2017-02-02\n",
      "Test max date data = 2020-02-18\n"
     ]
    }
   ],
   "source": [
    "# eje temporal de cada conjunto\n",
    "print('Train min date data = ' + np.amin(X_train_rand[\"fecha_salida\"]))\n",
    "print('Train max date data = ' + np.amax(X_train_rand[\"fecha_salida\"]))\n",
    "\n",
    "print('Val min date data = ' + np.amin(X_val_rand[\"fecha_salida\"]))\n",
    "print('Val max date data = ' + np.amax(X_val_rand[\"fecha_salida\"]))\n",
    "\n",
    "print('Test min date data = ' + np.amin(X_test_rand[\"fecha_salida\"]))\n",
    "print('Test max date data = ' + np.amax(X_test_rand[\"fecha_salida\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizamos las fecha de salida de los conjuntos para el set con el eje temporal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train min date data = 2017-02-02\n",
      "Train max date data = 2019-05-02\n",
      "Val min date data = 2019-05-03\n",
      "Val max date data = 2019-09-19\n",
      "Test min date data = 2019-09-19\n",
      "Test max date data = 2020-02-18\n"
     ]
    }
   ],
   "source": [
    "# eje temporal de cada conjunto\n",
    "print('Train min date data = ' + np.amin(X_train[\"fecha_salida\"]))\n",
    "print('Train max date data = ' + np.amax(X_train[\"fecha_salida\"]))\n",
    "\n",
    "print('Val min date data = ' + np.amin(X_val[\"fecha_salida\"]))\n",
    "print('Val max date data = ' + np.amax(X_val[\"fecha_salida\"]))\n",
    "\n",
    "print('Test min date data = ' + np.amin(X_test[\"fecha_salida\"]))\n",
    "print('Test max date data = ' + np.amax(X_test[\"fecha_salida\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podemos comprobar en este caso si varía.\n",
    "\n",
    "Si nuestro problema es time depending como en este caso, ya que no debería ver el llenado del vuelo en días posteriores es conveniente usar la segunda aproximación en la que al hacer el split de los conjuntos de train, validación y test estamos teniendo en cuenta el eje temporal.\n",
    "\n",
    "De otra manera nuestro modelo estaría haciendo \"trampa\" viendo el futuro."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez hechas las comprobaciones borramos la variable fecha_salida ya que no es una variable del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "del X_train['fecha_salida']\n",
    "del X_val['fecha_salida']\n",
    "del X_test['fecha_salida']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Modelos\n",
    "\n",
    "Scikit-Learn dispone de una extensa batería de modelos de Machine Learning disponible, siendo esta una de las grandes ventajas que tiene el uso de esta librería.\n",
    "\n",
    "Otra de las razones de su popularidad es que proporciona un framework de uso que es general para todos los tipos de modelos. Básicamente consiste de 6 pasos:\n",
    "\n",
    "1.Importar modelo que se quiere emplear. Ver lista de modelos supervisados en: https://scikit-learn.org/stable/supervised_learning.html\n",
    "\n",
    "\n",
    "2.Importa métrica a emplear. Ver lista de métricas disponibles en https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics.\n",
    "\n",
    "\n",
    "3.Definir modelo.\n",
    "\n",
    "\n",
    "4.Llamar al método fit para entrenar el modelo.\n",
    "\n",
    "\n",
    "5.Llamar al método predict para generar las predicciones.\n",
    "\n",
    "\n",
    "6.Calcular métrica usando las predicciones obtenidas en el paso anterior.\n",
    "\n",
    "\n",
    "Veamos todos estos pasos con un ejemplo sencillo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Importar modelo, en este caso usaremos una SVR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Importar métrica, en este caso MAE y MSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "from sklearn.metrics import mean_squared_error as mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Definir el método. Usaremos el kernel gaussiano ('rbf')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = svm.SVR(kernel='rbf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) Llamar al método fit para entrenar el modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Añadimos la función timeit para medir el tiempo que tarda el modelo.\n",
    "\n",
    "De esta manera podremos hacer una estimación de cuanto tardará nuestro grid. Aunque esto dependerá de muchas otras cosas, por ejemplo, el parámetro C da la complejidad del modelo y C más grande más tardará en entrenar ese modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time:  70.18509719999997\n"
     ]
    }
   ],
   "source": [
    "## Ponemos un contador para ver cuanto tarda cada modelo\n",
    "start = timeit.default_timer()\n",
    "\n",
    "model.fit(X_train, np.array(y_train))\n",
    "\n",
    "stop = timeit.default_timer()\n",
    "print('Time: ', stop - start) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5) Llamar al método predict para generar las predicciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time:  220.93040859999996\n"
     ]
    }
   ],
   "source": [
    "start = timeit.default_timer()\n",
    "\n",
    "pred_train = model.predict(X_train)\n",
    "pred_val = model.predict(X_val)\n",
    "pred_test = model.predict(X_test)\n",
    "\n",
    "stop = timeit.default_timer()\n",
    "print('Time: ', stop - start) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[143.22017172 132.00128753 114.21579788 114.53552318 132.92709824]\n",
      "[167 116 106  71 112]\n"
     ]
    }
   ],
   "source": [
    "# Comprobamos las primeras predicciones\n",
    "print(pred_train[0:5])\n",
    "print(y_train[0:5].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6) Calcular métrica usando las predicciones obtenidas en el paso anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular métricas de evaluación\n",
    "mae_train = mae(y_train, pred_train);\n",
    "mae_val = mae(y_val, pred_val);\n",
    "mae_test = mae(y_test, pred_test);\n",
    "\n",
    "mse_train = mse(y_train, pred_train);\n",
    "mse_val = mse(y_val, pred_val);\n",
    "mse_test = mse(y_test, pred_test);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: MAE = 18.60794422185709 - MSE = 618.8462335642462\n",
      "Validation: MAE = 17.540259525501458 - MSE = 511.740485906785\n",
      "Test: MAE = 21.87766070132835 - MSE = 838.4710150030895\n"
     ]
    }
   ],
   "source": [
    "print('Train: MAE = ' + str(mae_train) + ' - MSE = '  + str(mse_train))\n",
    "print('Validation: MAE = ' + str(mae_val) + ' - MSE = '  + str(mse_val))\n",
    "print('Test: MAE = ' + str(mae_test) + ' - MSE = '  + str(mse_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculamos una nueva métrica el MAPE, que tienen en cuenta el rango del target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mape(y_true, y_pred):\n",
    "    return np.mean(np.abs(y_true - y_pred)/y_pred) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular métricas de evaluación\n",
    "mape_train = mape(y_train, pred_train);\n",
    "mape_val = mape(y_val, pred_val);\n",
    "mape_test = mape(y_test, pred_test);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: MAPE = 14.685707851101155\n",
      "Validation: MAPE = 13.10264792424986\n",
      "Test: MAPE = 17.05901430581162\n"
     ]
    }
   ],
   "source": [
    "print('Train: MAPE = ' + str(mape_train))\n",
    "print('Validation: MAPE = ' + str(mape_val))\n",
    "print('Test: MAPE = ' + str(mape_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exhaustive Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos la rejilla de hiperparámetros a probar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': [0.1, 1, 10, 100],\n",
       " 'gamma': [0.01, 0.1, 0.001],\n",
       " 'epsilon': [1, 0.1],\n",
       " 'kernel': ['rbf']}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = [\n",
    "  {'C': [0.1, 1, 10, 100], 'gamma': [0.01, 0.1, 0.001],'epsilon': [1, 0.1],  'kernel': ['rbf']}\n",
    " ]\n",
    "params_values = param_grid[0]\n",
    "params_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculamos el numero de iteraciones totales como la multiplicación de la longitud de los posibles valores de todos los hiperaparámetros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El numero de iteraciones es 24\n"
     ]
    }
   ],
   "source": [
    "num_iteraciones = len(params_values['C'])*\n",
    "                  len(params_values['gamma'])*\n",
    "                  len(params_values['epsilon'])\n",
    "\n",
    "print('El numero de iteraciones es', num_iteraciones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = params_values['kernel'][0]\n",
    "metric = mae\n",
    "error_val = pd.DataFrame(columns=('err_val', 'C', 'gamma', 'epsilon'))\n",
    "num_iter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parametro C = 0.1, parametro gamma = 0.01, parametro epsilon = 1\n",
      "Error validacion = 20.40455387993815\n",
      "Parametro C = 0.1, parametro gamma = 0.01, parametro epsilon = 0.1\n",
      "Error validacion = 20.40973137687326\n",
      "Parametro C = 0.1, parametro gamma = 0.1, parametro epsilon = 1\n",
      "Error validacion = 22.032192335086034\n",
      "Parametro C = 0.1, parametro gamma = 0.1, parametro epsilon = 0.1\n",
      "Error validacion = 22.03951045806986\n",
      "Parametro C = 0.1, parametro gamma = 0.001, parametro epsilon = 1\n",
      "Error validacion = 21.46184102349487\n",
      "Parametro C = 0.1, parametro gamma = 0.001, parametro epsilon = 0.1\n",
      "Error validacion = 21.439377646975522\n",
      "Parametro C = 1, parametro gamma = 0.01, parametro epsilon = 1\n",
      "Error validacion = 17.643435784616543\n",
      "Parametro C = 1, parametro gamma = 0.01, parametro epsilon = 0.1\n",
      "Error validacion = 17.689505238607655\n",
      "Parametro C = 1, parametro gamma = 0.1, parametro epsilon = 1\n",
      "Error validacion = 21.337792746335168\n",
      "Parametro C = 1, parametro gamma = 0.1, parametro epsilon = 0.1\n",
      "Error validacion = 21.319187743402107\n",
      "Parametro C = 1, parametro gamma = 0.001, parametro epsilon = 1\n",
      "Error validacion = 19.603930293014006\n",
      "Parametro C = 1, parametro gamma = 0.001, parametro epsilon = 0.1\n",
      "Error validacion = 19.5828558954319\n",
      "Parametro C = 10, parametro gamma = 0.01, parametro epsilon = 1\n",
      "Error validacion = 16.354480112707733\n",
      "Parametro C = 10, parametro gamma = 0.01, parametro epsilon = 0.1\n",
      "Error validacion = 16.396507644961062\n",
      "Parametro C = 10, parametro gamma = 0.1, parametro epsilon = 1\n",
      "Error validacion = 19.29610993607658\n",
      "Parametro C = 10, parametro gamma = 0.1, parametro epsilon = 0.1\n",
      "Error validacion = 19.264647116822573\n",
      "Parametro C = 10, parametro gamma = 0.001, parametro epsilon = 1\n",
      "Error validacion = 18.026179625529405\n",
      "Parametro C = 10, parametro gamma = 0.001, parametro epsilon = 0.1\n",
      "Error validacion = 17.99246763874587\n",
      "Parametro C = 100, parametro gamma = 0.01, parametro epsilon = 1\n",
      "Error validacion = 16.948537694409044\n",
      "Parametro C = 100, parametro gamma = 0.01, parametro epsilon = 0.1\n",
      "Error validacion = 16.937849487727547\n",
      "Parametro C = 100, parametro gamma = 0.1, parametro epsilon = 1\n",
      "Error validacion = 19.26152918500393\n",
      "Parametro C = 100, parametro gamma = 0.1, parametro epsilon = 0.1\n",
      "Error validacion = 19.237520591393235\n",
      "Parametro C = 100, parametro gamma = 0.001, parametro epsilon = 1\n",
      "Error validacion = 16.587507123966713\n",
      "Parametro C = 100, parametro gamma = 0.001, parametro epsilon = 0.1\n",
      "Error validacion = 16.599121594468727\n",
      "Time:  1934.2476671999998\n"
     ]
    }
   ],
   "source": [
    "start = timeit.default_timer()\n",
    "\n",
    "for i in range(0,len(params_values['C'])):\n",
    "    for j in range(0,len(params_values['gamma'])):\n",
    "        for k in range(0,len(params_values['epsilon'])):\n",
    "            \n",
    "            # print control iteracion modelo\n",
    "            print('Parametro C = ' + str(params_values['C'][i]) + \n",
    "                  ', parametro gamma = '  + str(params_values['gamma'][j]) +\n",
    "                  ', parametro epsilon = '  + str(params_values['epsilon'][k]))\n",
    "            \n",
    "            # definicion del modelo con sus parametros\n",
    "            model = svm.SVR(kernel=kernel, C=params_values['C'][i],\n",
    "                            gamma=params_values['gamma'][j],\n",
    "                            epsilon=params_values['epsilon'][k])\n",
    "            \n",
    "            # entrenamiento del modelo\n",
    "            model.fit(X_train, np.array(y_train))\n",
    "            \n",
    "            # prediccion del conjunto de validacion\n",
    "            pred_val = model.predict(X_val)\n",
    "            \n",
    "            # Calculo de la metrica de error\n",
    "            error_val_iter = metric(y_val, pred_val)\n",
    "            \n",
    "            # print error\n",
    "            print('Error validacion = ' + str(error_val_iter))\n",
    "            \n",
    "            # guarda el error\n",
    "            error_val.loc[num_iter]=[error_val_iter,\n",
    "                                          params_values['C'][i],\n",
    "                                          params_values['gamma'][j],\n",
    "                                          params_values['epsilon'][k]] \n",
    "            num_iter += 1\n",
    "\n",
    "stop = timeit.default_timer()\n",
    "print('Time: ', stop - start) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mostramos la tabla del error de validacion segun los diferentes parametros para elegir el modelo que mejor se ajuste a nuestros datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>err_val</th>\n",
       "      <th>C</th>\n",
       "      <th>gamma</th>\n",
       "      <th>epsilon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20.404554</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.010</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.409731</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22.032192</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.100</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22.039510</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21.461841</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>21.439378</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>17.643436</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>17.689505</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>21.337793</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.100</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>21.319188</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>19.603930</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>19.582856</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>16.354480</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>16.396508</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>19.296110</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.100</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>19.264647</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>18.026180</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17.992468</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>16.948538</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>16.937849</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>19.261529</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.100</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>19.237521</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>16.587507</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>16.599122</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      err_val      C  gamma  epsilon\n",
       "0   20.404554    0.1  0.010      1.0\n",
       "1   20.409731    0.1  0.010      0.1\n",
       "2   22.032192    0.1  0.100      1.0\n",
       "3   22.039510    0.1  0.100      0.1\n",
       "4   21.461841    0.1  0.001      1.0\n",
       "5   21.439378    0.1  0.001      0.1\n",
       "6   17.643436    1.0  0.010      1.0\n",
       "7   17.689505    1.0  0.010      0.1\n",
       "8   21.337793    1.0  0.100      1.0\n",
       "9   21.319188    1.0  0.100      0.1\n",
       "10  19.603930    1.0  0.001      1.0\n",
       "11  19.582856    1.0  0.001      0.1\n",
       "12  16.354480   10.0  0.010      1.0\n",
       "13  16.396508   10.0  0.010      0.1\n",
       "14  19.296110   10.0  0.100      1.0\n",
       "15  19.264647   10.0  0.100      0.1\n",
       "16  18.026180   10.0  0.001      1.0\n",
       "17  17.992468   10.0  0.001      0.1\n",
       "18  16.948538  100.0  0.010      1.0\n",
       "19  16.937849  100.0  0.010      0.1\n",
       "20  19.261529  100.0  0.100      1.0\n",
       "21  19.237521  100.0  0.100      0.1\n",
       "22  16.587507  100.0  0.001      1.0\n",
       "23  16.599122  100.0  0.001      0.1"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Elegimos el modelo que menor error de validacion tenga"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "err_val    16.35448\n",
       "C          10.00000\n",
       "gamma       0.01000\n",
       "epsilon     1.00000\n",
       "Name: 12, dtype: float64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind_min = error_val['err_val'].idxmin()\n",
    "best_parameters = error_val.iloc[ind_min]\n",
    "best_parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reentrenamos el modelo con los parámetros óptimos y testeamos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = svm.SVR(kernel=kernel, C = best_parameters['C'],\n",
    "                gamma = best_parameters['gamma'], epsilon = best_parameters['epsilon'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Juntamos train y val para entrenar el modelo final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data size = (23969, 71)\n",
      "Train target size = (23969,)\n",
      "Validation data size = (5136, 71)\n",
      "Validation target size = (5136,)\n",
      "Train data size = (29105, 71)\n",
      "Train target size = (29105,)\n"
     ]
    }
   ],
   "source": [
    "print('Train data size = ' + str(X_train.shape))\n",
    "print('Train target size = ' + str(y_train.shape))\n",
    "print('Validation data size = ' + str(X_val.shape))\n",
    "print('Validation target size = ' + str(y_val.shape))\n",
    "\n",
    "# Combinar train y validación\n",
    "X_train = pd.concat((X_train,X_val), axis = 0)\n",
    "y_train = np.concatenate((y_train, y_val), axis = 0)\n",
    "\n",
    "print('Train data size = ' + str(X_train.shape))\n",
    "print('Train target size = ' + str(y_train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time:  106.25897079999982\n"
     ]
    }
   ],
   "source": [
    "## Ponemos un contador para ver cuanto tarda cada modelo\n",
    "start = timeit.default_timer()\n",
    "\n",
    "model.fit(X_train, np.array(y_train))\n",
    "\n",
    "stop = timeit.default_timer()\n",
    "print('Time: ', stop - start) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time:  283.93091949999985\n"
     ]
    }
   ],
   "source": [
    "start = timeit.default_timer()\n",
    "\n",
    "pred_train = model.predict(X_train)\n",
    "pred_val = model.predict(X_val)\n",
    "pred_test = model.predict(X_test)\n",
    "\n",
    "stop = timeit.default_timer()\n",
    "print('Time: ', stop - start) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular métricas de evaluación\n",
    "mae_train = mae(y_train, pred_train);\n",
    "mae_test = mae(y_test, pred_test);\n",
    "\n",
    "mse_train = mse(y_train, pred_train);\n",
    "mse_test = mse(y_test, pred_test);\n",
    "\n",
    "mape_train = mape(y_train, pred_train);\n",
    "mape_test = mape(y_test, pred_test);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: MAE = 15.444501332459385 - MSE = 452.43111899684897 - MAPE =12.382034804673726\n",
      "Test: MAE = 20.141798633773345 - MSE = 726.6233340457293 - MAPE =15.969432382780926\n"
     ]
    }
   ],
   "source": [
    "print('Train: MAE = ' + str(mae_train) + ' - MSE = '  + str(mse_train) + ' - MAPE =' + str(mape_train))\n",
    "print('Test: MAE = ' + str(mae_test) + ' - MSE = '  + str(mse_test) + ' - MAPE =' + str(mape_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
